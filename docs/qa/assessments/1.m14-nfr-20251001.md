# NFR Assessment: Story 1.M14 - MÃ³dulo AutoAvaliaÃ§Ã£o

Date: 2025-10-01
Reviewer: Quinn (Test Architect)

**Status**: PLANNING - NFR baseline for implementation with focus on psychological safety and privacy

## Summary

- **Security & Privacy**: CONCERNS - Student data protection critical, RLS enforcement essential
- **Psychological Safety**: CONCERNS - Core requirement, needs extensive validation
- **Performance**: PASS - Simple UI, low computational needs
- **Reliability**: PASS - Straightforward data collection, minimal error scenarios
- **Usability (Emotional Impact)**: CONCERNS - Must validate with target age group
- **Maintainability**: PASS - Modular design, clear data structure

**Quality Score**: 65/100 (Planning baseline - reflects high sensitivity of psychological safety requirements)

## Detailed Assessment

### 1. Security & Privacy - CONCERNS

**Status**: CONCERNS (critical protection needed for sensitive student data)
**Target**: Student self-assessment responses confidential, never exposed to peers

#### Requirements Analysis

From story AC-2, Psychological Design Principles, and Definition of Done:
- Private responses (not shared with peers)
- Teacher dashboard shows trends, not individual raw responses in peer-visible context
- LGPD considerations (Brazilian data protection)
- Student self-assessment is vulnerable personal data

#### Assessment

**Positive Indicators**:
- Story explicitly states "Private responses (not shared with peers)"
- Supabase Row Level Security (RLS) mentioned in integration
- Data structure separates student interactions (private) from aggregated teacher insights

**Critical Gaps Identified**:
1. **No RLS policy specification** - Database security rules not documented
2. **No access control matrix** - Who can see what data?
3. **No privacy testing strategy** - How to verify peer isolation?
4. **LGPD compliance not addressed** - Consent, data retention, right to deletion
5. **No session isolation strategy** - Multiple students on same device?

#### Required Privacy Mitigations

**Must Implement**:
```sql
-- Supabase RLS Policy Examples (must be formalized)
-- Student can only see their own self-assessments
CREATE POLICY "Students see own data only"
ON student_progress
FOR SELECT
USING (auth.uid() = student_id);

-- Teachers can see aggregated data for their students
-- (implement appropriate teacher-student relationships)
CREATE POLICY "Teachers see aggregated student data"
ON concept_mastery
FOR SELECT
USING (teacher_id_matches(auth.uid(), student_id));

-- NO peer-to-peer access
CREATE POLICY "Block peer access"
ON student_progress
FOR ALL
USING (false)  -- No student can access another student's raw data
WITH CHECK (false);
```

**Privacy Architecture**:
- **Student View**: Can only query `WHERE student_id = current_user_id`
- **Teacher View**: Can query aggregated data for their class
- **Peer View**: No access to individual self-assessments at all
- **Admin View**: Aggregated anonymized data only

**Data Retention**:
- Define retention policy (keep for 1 academic year? 2 years?)
- Implement data deletion on student graduation/transfer
- Parent/guardian right to request data deletion (LGPD Art. 18)

**Testing Requirements**:
- [ ] Write and test RLS policies for all student_progress operations
- [ ] Security audit: Attempt cross-student data access (should fail)
- [ ] UI audit: Verify no peer response visibility
- [ ] Session isolation: Test multiple students on shared device
- [ ] LGPD compliance review (legal consultation)
- [ ] Privacy impact assessment (PIA)

**Recommendation**: Create privacy architecture document and RLS policy specification before implementation.

---

### 2. Psychological Safety - CONCERNS

**Status**: CONCERNS (core functional requirement, needs extensive validation)
**Target**: Students feel safe to be honest about struggles, no fear of judgment

#### Requirements Analysis

From story Psychological Design Principles:
- No wrong answers emphasized repeatedly
- Warm, non-judgmental color palette
- Growth mindset language throughout
- Private responses (not shared with peers)
- All responses validated positively

#### Assessment

**Positive Indicators**:
- Story dedicates entire section to "Psychological Design Principles"
- Specific color palette choices (warm, non-judgmental)
- Response messages designed for all selections
- Growth mindset language ("Preciso praticar mais" not "NÃ£o sei")
- Emojis chosen for warmth (ðŸ˜…ðŸ™‚ðŸ˜ŠðŸŒŸ) not judgment

**Critical Gaps Identified**:
1. **No validation with target age group** - Assumptions about 4th-6th graders not tested
2. **No A/B testing plan** - How to optimize tone/messaging?
3. **No teacher training plan** - Teachers could undermine safety through reactions
4. **No measurement strategy** - How to detect safety failures?
5. **No cultural sensitivity review** - Brazilian educational context nuances?

#### Required Psychological Safety Validations

**User Testing Protocol** (Must Complete Before Production):

**Phase 1: Alpha Testing (n=10 students)**
- Observe facial expressions and body language during use
- Exit interview questions:
  - "How did this activity make you feel?" (open-ended)
  - "Did you feel comfortable being honest?" (yes/no/sort of)
  - "Would you change anything about the questions or answers?" (open-ended)
- Track response distribution (clustering at "safe" answers suggests fear)

**Phase 2: A/B Testing (n=40 students, 2 groups)**
- Group A: Current design
- Group B: Alternative message tone (more neutral vs current encouraging)
- Measure: Completion rate, response distribution, emotional response survey
- Goal: Identify which design promotes honest self-reflection

**Phase 3: Long-term Monitoring (4 weeks)**
- Track calibration accuracy over time (improving = students getting honest)
- Monitor for "safe answer clustering" (everyone picking "3")
- Student satisfaction surveys
- Teacher observations of student engagement

**Teacher Training Requirements**:
- Module explaining psychological safety principles
- Examples of supportive responses to self-assessments
- RED FLAG responses (avoid judgmental reactions)
- Role-playing scenarios

**Cultural Sensitivity**:
- Review by Brazilian elementary educators
- Consideration of regional language variations
- Understanding of local school culture (competitive vs collaborative)

**Testing Requirements**:
- [ ] Alpha testing with 10 students (qualitative)
- [ ] A/B testing with 40 students (quantitative)
- [ ] Long-term monitoring (4 weeks) with pattern analysis
- [ ] Teacher training comprehension assessment
- [ ] Cultural sensitivity review by Brazilian educator
- [ ] Emotional response measurement (validated survey instrument)

**Recommendation**: Psychological safety validation MUST happen with real students before production rollout. Cannot rely on adult assumptions about child psychology.

---

### 3. Performance - PASS

**Status**: PASS (simple UI, low computational requirements)
**Targets**:
- Self-assessment completion: <3 minutes âœ“ (specified in story)
- Response recording: <100ms âœ“ (reasonable target)
- Teacher dashboard calibration: <3s âœ“ (aggregation query)

#### Assessment

**Positive Indicators**:
- Module is intentionally simple (2-3 questions max)
- Large buttons, single-click responses (no complex interactions)
- Minimal data to process (4-point scale, 2-3 concepts)
- No heavy visualizations in student view
- Clear time constraint (1-3 minutes maximum)

**Performance Characteristics**:

**Student View (Critical Path)**:
1. Module loads: <2s (inherits from US-001 ModuleRuntime)
2. Question renders: <500ms (simple text + buttons)
3. Student clicks response: Immediate feedback (<100ms)
4. Response recorded: <200ms (Supabase insert)
5. Transition to next question/completion: <500ms
6. **Total time: 2-3 minutes** (human pace, not technical bottleneck)

**Teacher Dashboard (Non-critical)**:
1. Aggregated calibration query: <3s (acceptable for teacher use)
2. Chart rendering: <1s (simple trend line)
3. Student detail view: <2s (pre-aggregated data)

**No Performance Concerns**:
- No real-time processing
- No complex algorithms in UI
- No large dataset rendering in student view
- Teacher dashboard can use caching (refresh every 5 min)

**Testing Requirements**:
- [ ] Module load time <2s (inherits US-001 testing)
- [ ] Response recording <200ms (integration test)
- [ ] Teacher dashboard query <3s (with 30 students, 12 weeks data)
- [ ] User perception test (does 2-3min feel too long?)

**Recommendation**: Performance is not a concern. Focus testing on user perception of time (fatigue) rather than technical speed.

---

### 4. Reliability - PASS

**Status**: PASS (straightforward data collection, minimal failure modes)
**Target**: No data loss, graceful handling of edge cases

#### Assessment

**Positive Indicators**:
- Simple data structure (JSON in student_progress.interactions)
- Auto-save after each response (no batch submission risk)
- Integration with proven infrastructure (Supabase)
- No complex state management (stateless questions)

**Failure Modes (All Addressable)**:

**1. Network Interruption During Response**
- **Mitigation**: Save to localStorage immediately, sync to Supabase when online
- **User Experience**: "Response saved, will sync when online"
- **Testing**: Offline mode simulation

**2. Student Closes Browser Mid-Assessment**
- **Mitigation**: Auto-save after each response, mark as "partial completion"
- **User Experience**: Resume from last answered question (or mark complete if â‰¥2/3 answered)
- **Testing**: Browser close simulation

**3. Multiple Concepts Assessed, One Fails to Save**
- **Mitigation**: Save each concept assessment independently (atomic operations)
- **User Experience**: Retry failed saves in background
- **Testing**: Database failure injection

**4. Duplicate Submissions (Double-click)**
- **Mitigation**: Disable button after click, idempotency key in database
- **User Experience**: No duplicate data recorded
- **Testing**: Rapid double-click simulation

**Reliability Requirements**:
- Auto-save to localStorage after each response (<100ms)
- Sync to Supabase (retry 3 times with exponential backoff)
- Mark activity as "partially complete" if self-assessment skipped
- Alert teacher if student consistently skips (>3 sessions)
- No data loss scenarios (verified through testing)

**Testing Requirements**:
- [ ] Network interruption recovery (offline â†’ online transition)
- [ ] Browser close recovery (localStorage persistence)
- [ ] Partial completion handling
- [ ] Duplicate submission prevention
- [ ] Retry logic verification (exponential backoff)

**Recommendation**: Reliability risks are low and well-understood. Standard web app error handling sufficient.

---

### 5. Usability (Emotional Impact) - CONCERNS

**Status**: CONCERNS (subjective, requires validation with target users)
**Target**: Students find experience encouraging, not stressful

#### Requirements Analysis

From story UI/UX Requirements and Educational Outcomes:
- Large, friendly buttons with emojis (48px+ height)
- Soft, warm colors (no harsh red/green judgments)
- Question text: 20px/700/Atkinson Hyperlegible
- Encouraging message: "NÃ£o hÃ¡ resposta errada! Seja honesto sobre como se sente"

#### Assessment

**Positive Indicators**:
- Clear design specifications (button size, typography, colors)
- Emoji choices convey warmth (ðŸ˜…ðŸ™‚ðŸ˜ŠðŸŒŸ)
- Color palette explicitly avoids judgment (no red/green)
- Layout example provided in story
- Accessibility considered (screen readers, keyboard)

**Subjective Concerns Requiring Validation**:

**1. Emoji Interpretation**
- **Question**: Do 4th-6th graders interpret ðŸ˜… as "struggling but okay" or "embarrassed"?
- **Question**: Is ðŸŒŸ aspirational or pressure-inducing?
- **Validation**: User testing with emoji preference ranking

**2. Response Label Language**
- **Current**: "Preciso praticar mais" (I need more practice)
- **Alternative**: "Ainda estou aprendendo" (I'm still learning)
- **Question**: Which feels less judgmental to students?
- **Validation**: A/B testing with qualitative feedback

**3. Visual Density**
- **Question**: Is 4 buttons overwhelming or manageable for 4th graders?
- **Question**: Is spacing adequate to prevent accidental clicks?
- **Validation**: Usability testing with youngest target age (9-year-olds)

**4. Reading Level**
- **Requirement**: 4th grade reading level (Flesch-Kincaid Grade 4-5)
- **Current question**: "Como vocÃª se sente sobre divisÃ£o agora?"
- **Analysis needed**: Readability score verification
- **Validation**: Comprehension testing with 4th graders

**5. Emoji Rendering Consistency**
- **Risk**: Emojis look different on Windows vs macOS vs Android
- **Impact**: Tone/meaning could change across platforms
- **Mitigation**: Use Twemoji or custom SVG emojis
- **Validation**: Cross-platform visual audit

**Usability Testing Requirements**:
- [ ] Emoji interpretation study (n=20 students)
- [ ] Response label preference testing (A/B)
- [ ] Visual density/spacing usability test
- [ ] Readability analysis (Flesch-Kincaid)
- [ ] 4th grade comprehension testing
- [ ] Cross-platform emoji rendering audit
- [ ] Accessibility audit (keyboard navigation, screen readers)

**Recommendation**: Usability MUST be validated with actual 4th-6th grade Brazilian students. Adult assumptions are insufficient for this age group.

---

### 6. Maintainability - PASS

**Status**: PASS (modular design, clear data structure, configurable)
**Target**: Easy to modify question templates, scale options, response messages

#### Assessment

**Positive Indicators**:
- JSON configuration for flexibility:
  - `scaleType: "4-point"` (can change to 3 or 5)
  - `questionTemplate` allows customization
  - Response options as data (easy to modify)
- Clear data structure (`student_progress.interactions`)
- Integration with existing teacher dashboard
- Follows module pattern from US-001 (consistency)

**Maintainability Strengths**:

**1. Configuration-Driven**:
```json
{
  "moduleType": "AutoAvaliaÃ§Ã£o",
  "config": {
    "scaleType": "4-point",
    "questionTemplate": "Como vocÃª se sente sobre {concept} agora?",
    "options": [ /* easy to modify */ ]
  }
}
```
- Changing tone/language doesn't require code changes
- A/B testing different scales is configuration change
- Teacher can customize per activity

**2. Data Structure Clarity**:
```javascript
{
  type: "self_assessment",
  assessments: [
    {
      concept: "divisÃ£o",
      selfRating: 2,
      actualPerformance: 0.75,
      discrepancy: -0.25
    }
  ]
}
```
- Clear semantics (self-explanatory field names)
- Easy to query for analytics
- Schema supports future enhancements (confidence, emotionalState)

**3. Integration Points Well-Defined**:
- Activity completion flow: Appears at end of practice sessions
- Teacher dashboard: Aggregated calibration trends
- Concept mastery: Feeds into adaptive progression

**Areas for Enhancement**:
- **Documentation**: Add inline comments explaining calibration calculation
- **Testing**: Unit tests for calibration discrepancy logic
- **Versioning**: Add `schemaVersion` to future-proof data structure
- **Localization**: Prepare for multi-language support (separate content from code)

**Testing Requirements**:
- [ ] Unit tests for configuration parsing
- [ ] Unit tests for calibration calculation
- [ ] Integration tests for data persistence
- [ ] Documentation completeness review
- [ ] Schema versioning implementation

**Recommendation**: Maintainability is strong. Focus on documentation and unit testing for calibration logic.

---

## Critical NFR Issues

### Issue 1: Privacy Architecture Undefined

**Category**: Security & Privacy
**Severity**: CRITICAL
**Risk**: Student self-assessments could be exposed to peers
**Recommendation**:
- Define Supabase RLS policies before implementation
- Create access control matrix (student/teacher/admin)
- Implement session isolation strategy
- Security audit with penetration testing
- LGPD compliance review

**Effort**: ~12 hours (architecture + implementation + testing)

---

### Issue 2: Psychological Safety Not Validated

**Category**: Psychological Safety (Core Functional Requirement)
**Severity**: CRITICAL
**Risk**: Students fear judgment, give dishonest responses, module fails core purpose
**Recommendation**:
- Alpha testing with 10 students (qualitative feedback)
- A/B testing with 40 students (message tone variations)
- Long-term monitoring (4 weeks) for pattern analysis
- Teacher training on supportive responses
- Cultural sensitivity review

**Effort**: ~40 hours (planning + recruitment + testing + analysis + iteration)

---

### Issue 3: Usability Assumptions Not Validated with Target Age Group

**Category**: Usability & Emotional Impact
**Severity**: HIGH
**Risk**: Language too complex, emojis misinterpreted, UI overwhelming for 4th graders
**Recommendation**:
- Readability analysis (target Flesch-Kincaid Grade 4)
- 4th grade comprehension testing
- Emoji interpretation study
- Usability testing with youngest target age
- Cross-platform emoji rendering audit

**Effort**: ~24 hours (testing + iteration)

---

### Issue 4: Teacher Training Not Designed

**Category**: Psychological Safety & Data Misuse Prevention
**Severity**: HIGH
**Risk**: Teachers misuse calibration data, undermine psychological safety
**Recommendation**:
- Create teacher training module (calibration interpretation)
- Role-playing scenarios (appropriate responses)
- Red flag language guidelines (judgmental vs supportive)
- Comprehension assessment after training
- Ongoing teacher support resources

**Effort**: ~16 hours (content creation + validation)

---

## Quick Wins (Low Effort, High Value)

1. **Readability analysis** (~1 hour) - Flesch-Kincaid score for all text
2. **RLS policy draft** (~2 hours) - Initial security rules specification
3. **Emoji rendering test** (~2 hours) - Cross-platform visual audit
4. **Calibration algorithm unit tests** (~4 hours) - Verify discrepancy calculation
5. **Privacy checklist** (~2 hours) - LGPD compliance review template

---

## NFR Validation Checklist

Before marking story as "Done", verify:

### Security & Privacy âœ“
- [ ] Supabase RLS policies implemented and tested
- [ ] Cross-student data access blocked (penetration test passed)
- [ ] UI audit confirms no peer response visibility
- [ ] Session isolation on shared devices working
- [ ] LGPD compliance reviewed (consent, retention, deletion)
- [ ] Privacy Impact Assessment (PIA) completed

### Psychological Safety âœ“
- [ ] Alpha testing with 10 students completed (positive feedback)
- [ ] A/B testing with 40 students shows encouraging design is optimal
- [ ] Long-term monitoring (4 weeks) shows no "safe answer clustering"
- [ ] Teacher training module created and validated
- [ ] Cultural sensitivity review by Brazilian educator approved
- [ ] No student complaints about feeling judged (monitoring ongoing)

### Performance âœ“
- [ ] Module load time <2s verified (inherits US-001)
- [ ] Response recording <200ms verified
- [ ] Teacher dashboard calibration query <3s (30 students, 12 weeks)
- [ ] User perception: 2-3min feels appropriate (not too long)

### Reliability âœ“
- [ ] Network interruption recovery working (localStorage â†’ Supabase)
- [ ] Browser close recovery working (partial completion handling)
- [ ] Duplicate submission prevention verified
- [ ] Retry logic with exponential backoff tested
- [ ] No data loss scenarios (integration tests passing)

### Usability (Emotional Impact) âœ“
- [ ] Readability analysis: Flesch-Kincaid Grade 4-5 achieved
- [ ] 4th grade comprehension testing: 90%+ understand questions
- [ ] Emoji interpretation study: Emojis convey intended warmth
- [ ] Usability testing: 4th graders navigate easily (no confusion)
- [ ] Cross-platform emoji rendering consistent (Twemoji or SVG)
- [ ] Accessibility audit passed (WCAG AA, keyboard, screen readers)

### Maintainability âœ“
- [ ] Unit tests for configuration parsing (coverage >90%)
- [ ] Unit tests for calibration calculation (edge cases covered)
- [ ] Integration tests for data persistence passing
- [ ] Documentation complete (inline comments, teacher guide)
- [ ] Schema versioning implemented

---

## Integration with Quality Gate

**Gate NFR Block** (for gate file):

```yaml
nfr_validation:
  _assessed: [security_privacy, psychological_safety, performance, reliability, usability_emotional_impact, maintainability]
  _status: PLANNING

  security_privacy:
    status: CONCERNS
    notes: 'RLS policies and privacy architecture must be defined before implementation'
    blockers:
      - 'Define Supabase RLS policies (student/teacher access)'
      - 'Create privacy architecture document'
      - 'Plan LGPD compliance (consent, retention, deletion)'
      - 'Security audit plan (penetration testing)'
    timeline: 'Before implementation begins'

  psychological_safety:
    status: CONCERNS
    notes: 'Core functional requirement - must validate with actual students'
    blockers:
      - 'Alpha testing with 10 students (qualitative)'
      - 'A/B testing with 40 students (message tone)'
      - 'Long-term monitoring plan (4 weeks pattern analysis)'
      - 'Teacher training module design'
    timeline: 'Before production rollout'

  performance:
    status: PASS
    notes: 'Simple UI, low computational needs, inherits US-001 performance'
    requirements:
      - 'Module load <2s (US-001 baseline)'
      - 'Response recording <200ms'
      - 'Teacher dashboard <3s'
    validation: 'Standard performance testing sufficient'

  reliability:
    status: PASS
    notes: 'Straightforward data collection, standard web app error handling'
    requirements:
      - 'Auto-save to localStorage + Supabase'
      - 'Network interruption recovery'
      - 'Partial completion handling'
    validation: 'Integration tests cover main failure modes'

  usability_emotional_impact:
    status: CONCERNS
    notes: 'Subjective, requires validation with 4th-6th grade students'
    blockers:
      - 'Readability analysis (Flesch-Kincaid Grade 4-5)'
      - '4th grade comprehension testing'
      - 'Emoji interpretation study'
      - 'Usability testing with youngest age (9 years)'
      - 'Cross-platform emoji rendering audit'
    timeline: 'During alpha/beta testing'

  maintainability:
    status: PASS
    notes: 'Modular design, clear data structure, configuration-driven'
    requirements:
      - 'Unit tests for calibration logic'
      - 'Documentation for teacher customization'
      - 'Schema versioning for future changes'
    validation: 'Code review + unit tests'
```

**Recommended Gate Decision**: CONCERNS - PENDING IMPLEMENTATION AND VALIDATION

**Rationale**: Story has clear design principles and good technical foundation, but critical validations with target age group (psychological safety, usability, emotional impact) MUST happen before production. Privacy architecture must be formalized. Cannot rely on adult assumptions about 4th-6th grade psychology.

---

## Appendix: ISO 25010 Mapping

### Assessed Characteristics

1. **Security & Privacy** (6.1.5 + 6.1.6) - Confidentiality, Privacy compliance
   - Student data protection
   - RLS enforcement
   - LGPD compliance

2. **Psychological Safety** (Custom - Core Functional Requirement)
   - Non-judgmental design
   - Honest response encouragement
   - Growth mindset language

3. **Performance Efficiency** (6.1.2) - Time behavior
   - Module completion time <3min
   - Response recording speed
   - Dashboard query performance

4. **Reliability** (6.1.3) - Fault tolerance, Recoverability
   - Network interruption handling
   - Data persistence
   - Partial completion support

5. **Usability** (6.1.1) - Learnability, User error protection
   - Age-appropriate language
   - Emoji interpretation
   - Visual clarity

6. **Maintainability** (6.1.7) - Modifiability, Testability
   - Configuration-driven design
   - Clear data structures
   - Unit test coverage

### Not Assessed (Not Applicable for This Module)

- Compatibility: Single-app architecture
- Portability: Web-only at this stage
- Functional Suitability: Covered in acceptance criteria review

---

## Special Considerations for Educational Psychology

### Why This Module Requires Exceptional Care

Unlike technical modules (BateriaRÃ¡pida, IdentificaOperaÃ§Ã£o), AutoAvaliaÃ§Ã£o operates in sensitive psychological territory:

1. **Self-perception**: Students make vulnerable statements about their competence
2. **Honesty**: Requires trust that honesty won't be punished
3. **Metacognition**: Abstract concept difficult for concrete-operational thinkers (ages 7-11)
4. **Cultural context**: Brazilian educational culture around achievement and struggle

### Validation Cannot Be Skipped

**Why adult assumptions fail**:
- Adults forget what 4th grade reading level feels like
- Adults underestimate emoji interpretation differences
- Adults assume children understand abstract concepts (metacognition)
- Adults project their own comfort with vulnerability onto children

**Required approach**:
- Test with actual 4th-6th grade Brazilian students
- Observe behavior, not just surveys (facial expressions, hesitation)
- Iterate based on findings (not one-shot validation)
- Cultural sensitivity review by Brazilian elementary educators
- Teacher training on supportive responses

### Success Criteria

**Behavioral indicators of psychological safety**:
- Completion rate >90% (not avoiding the module)
- Response distribution varied (not clustering at "safe" answer)
- Time spent appropriate (not rushing through)
- Student sentiment positive/neutral (not anxious)
- Calibration accuracy improves over time (honesty increasing)

**Teacher behavior indicators**:
- Using calibration data formatively (not punitively)
- Supportive responses to struggles
- No complaints from students about feeling judged

---

**QA Contact**: For questions about this NFR assessment or validation protocols, contact Quinn (Test Architect).

**Next Steps**:
1. Review with PO/PM/UX-Expert - validate concerns and approach
2. Plan alpha testing recruitment (10 students, 4th-6th grade)
3. Draft RLS policies and privacy architecture
4. Begin teacher training content development
5. Schedule Brazilian educator cultural sensitivity review
