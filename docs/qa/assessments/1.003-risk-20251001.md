# Risk Profile: Story 1.003 - Sistema de Feedback Formativo

Date: 2025-10-01
Reviewer: Quinn (Test Architect)

## Executive Summary

- Total Risks Identified: 10
- Critical Risks: 3
- High Risks: 4
- Medium Risks: 3
- Risk Score: 42/100

**Status**: PLANNING - Risk assessment for implementation guidance with special focus on pedagogical quality and emotional impact

## Critical Risks Requiring Immediate Attention

### 1. PED-001: Inappropriate Feedback Language Causing Emotional Harm

**Score: 9 (Critical)**
**Probability**: High (3) - Complex to get tone right for 9-12 year olds
**Impact**: High (3) - Psychological harm, platform rejection, trust loss

**Description**: Feedback system is core to P2 principle "Feedback Formativo, Não Punitivo". Inappropriate tone (condescending, harsh, infantilizing) can cause psychological harm to vulnerable students, violating the platform's core pedagogical mission.

**Affected Components**:
- FeedbackEngine (message generation)
- Message bank (all content)
- Teacher configuration system
- Integration with all modules (M1, M5, M10, M14)

**Mitigation**:
- **User testing with 9-12 year olds is MANDATORY** (per DoD)
- Pedagogical expert review of all message content
- A/B testing framework for message optimization (per DoD)
- Teacher configuration for feedback style
- No launch without validated positive emotional response
- Establish forbidden words list: "wrong", "failed", "bad", "stupid", etc.
- Contextual examples in PRD reviewed by child psychologist

**Testing Requirements**:
- Emotional response testing with target age group (DoD requirement)
- Survey students after feedback interactions
- Measure engagement vs frustration metrics
- A/B test different message styles
- Pedagogical appropriateness review checklist
- Cross-cultural sensitivity validation

**Residual Risk**: Medium - Even with testing, individual reactions vary

**Owner**: ux-expert + qa (user testing coordination)
**Timeline**: BEFORE any production deployment, user testing in Sprint 2-3

### 2. PERF-001: Feedback Display Latency Exceeding 100ms Target

**Score: 9 (Critical)**
**Probability**: High (3) - Aggressive performance target, complex rendering
**Impact**: High (3) - Breaks immediacy, poor learning experience, frustration

**Description**: Story specifies <100ms feedback display after response submission. This is extremely aggressive for a system involving message selection, animation rendering, accessibility features, and audio synthesis.

**Affected Components**:
- FeedbackEngine.generateFeedback()
- Message selection algorithm
- Animation system (600ms duration but must START <100ms)
- Audio synthesis (Tone.js)
- Screen reader integration

**Mitigation**:
- Pre-compute and cache message variations
- Lazy load audio synthesis library
- Optimize animation rendering (CSS transforms, GPU acceleration)
- Performance budget per component:
  - Message selection: <30ms
  - Animation setup: <20ms
  - Audio trigger: <20ms
  - Accessibility prep: <20ms
  - Buffer: 10ms
- Progressive enhancement (audio/animations optional)
- Performance monitoring in production
- Benchmark on low-end devices (2GB RAM)

**Testing Requirements**:
- Performance benchmarks <100ms (P0 priority)
- Test on low-end devices (4GB RAM, older CPU)
- Network latency simulation
- High concurrent usage testing
- Regression testing for performance
- Real User Monitoring (RUM) post-launch

**Residual Risk**: Medium - Device variability may cause edge case failures

**Owner**: dev + qa (performance testing)
**Timeline**: Performance testing in every sprint, gate blocker

### 3. ACC-001: Screen Reader Feedback Accessibility Failures

**Score: 9 (Critical)**
**Probability**: High (3) - Complex interaction of visual + audio + SR
**Impact**: High (3) - Excludes visually impaired students, legal compliance

**Description**: Feedback must be accessible to screen readers (per story requirements). Visual feedback (colors, animations), audio feedback (optional tones), and semantic feedback (text) must work harmoniously for screen reader users. Timing and announcement order critical.

**Affected Components**:
- Visual feedback rendering (semantic colors)
- Audio feedback system (optional)
- ARIA live regions
- Focus management
- Animation timing with SR announcements

**Mitigation**:
- ARIA live regions for feedback announcements
- Semantic HTML structure
- Proper focus management (no focus traps)
- Screen reader testing with NVDA, JAWS, VoiceOver
- High contrast mode support
- Audio feedback optional (user preference)
- Clear visual AND textual feedback (not just color)
- Timing coordination (SR announces before animation completes)

**Testing Requirements**:
- Screen reader testing (NVDA, JAWS, VoiceOver) - P0
- WCAG 2.1 AA compliance validation
- Keyboard navigation testing
- High contrast mode testing
- Color blindness simulation
- Focus management validation
- User testing with visually impaired students (if possible)

**Residual Risk**: Low - With proper ARIA and testing

**Owner**: dev + ux-expert + qa (accessibility specialist)
**Timeline**: Accessibility testing in Sprint 2, gate blocker

## High Risks

### 4. REPO-001: Message Bank Repetition Causing Disengagement

**Score: 6 (High)**
**Probability**: Medium (2) - Limited message bank for MVP
**Impact**: High (3) - Student disengagement, perceived as robotic

**Description**: Story identifies "feedback becomes repetitive" as a risk. Students completing 30-problem BateriaRápida sessions will see feedback 30+ times. Without sufficient diversity, messages become stale and lose pedagogical value.

**Mitigation**:
- Message bank structure by: Subject × Concept × Type × Difficulty
- Minimum 10 variations per message category for MVP
- Message rotation algorithm (avoid same message twice in 10 interactions)
- Contextual variation based on student history
- A/B testing framework to identify stale messages
- Teacher feedback mechanism for message quality
- Post-MVP: Adaptive messages based on student profile

**Testing Requirements**:
- Message diversity validation (no repeats in 10 consecutive)
- Message bank coverage testing
- User testing for perceived repetition
- Long session testing (30+ interactions)

**Owner**: po + ux-expert (content creation)
**Timeline**: Message bank created Sprint 1-2, tested Sprint 2-3

### 5. INT-001: Integration Failures with US-001 Module Runtime

**Score: 6 (High)**
**Probability**: Medium (2) - Dependency on US-001 architecture
**Impact**: High (3) - Feedback system unusable across modules

**Description**: US-003 integrates with ALL module types (M1, M5, M10, M14 per story). If US-001 module runtime has issues OR if feedback integration points are poorly designed, feedback system fails globally.

**Affected Components**:
- Module response validation (each module type)
- Feedback trigger mechanism
- State integration with module state
- Animation rendering within module UI

**Mitigation**:
- **Verify US-001 quality gate is PASS before starting US-003**
- Define clear integration contract (FeedbackRequest/FeedbackResponse)
- Integration testing with all 4 MVP module types
- Mock module responses for isolated testing
- Error handling for invalid responses
- Fallback feedback if module integration fails

**Testing Requirements**:
- Integration tests with M1, M5, M10, M14 (P0)
- Invalid response handling tests
- State synchronization tests
- Cross-module consistency tests

**Owner**: dev + architect
**Timeline**: US-001 dependency verification before Sprint 1

### 6. PED-002: Feedback Tone Perceived as Condescending

**Score: 6 (High)**
**Probability**: Medium (2) - Subjective tone assessment
**Impact**: High (3) - Platform rejection, mission failure

**Description**: Story risk matrix identifies this explicitly. Language appropriate for 9-12 year olds is challenging - too simple feels infantilizing, too complex feels dismissive.

**Mitigation**:
- Pedagogical expert review of all messages
- User testing with 9-12 year olds (DoD requirement)
- A/B testing different tones
- Cultural sensitivity review
- Teacher customization of feedback style
- Clear writing guidelines for message authors
- Avoid: "Very good!", "Try harder!", "That's wrong"
- Prefer: Specific concept reinforcement, growth mindset language

**Testing Requirements**:
- Emotional response surveys (DoD requirement)
- User testing sessions with target demographic
- Cross-cultural validation (if multi-region)
- Teacher feedback collection

**Owner**: ux-expert + po
**Timeline**: User testing Sprint 2-3, iterative refinement

### 7. DATA-001: Feedback Context Loss on Module Transitions

**Score: 6 (High)**
**Probability**: Medium (2) - Complex state management across modules
**Impact**: High (3) - Inappropriate feedback, student confusion

**Description**: Feedback needs context from student's recent history (prior attempts, difficulty level, concept mastery). If context is lost during module transitions, feedback becomes generic and loses pedagogical value.

**Mitigation**:
- Persistent student context (localStorage + Supabase)
- Feedback history tracking (last 10 interactions)
- Graceful degradation if context unavailable
- Clear context requirements in FeedbackEngine API
- Integration with concept_mastery table

**Testing Requirements**:
- Context persistence tests across sessions
- Module transition context preservation
- Graceful degradation with missing context

**Owner**: dev
**Timeline**: Sprint 1-2 implementation

## Medium Risks

### 8. PERF-002: Animation Performance on Low-End Devices

**Score: 4 (Medium)**
**Probability**: Medium (2) - CSS animations generally fast
**Impact**: Medium (2) - Jarring experience, not blocking

**Description**: Animations (subtle-glow, gentle-shake) must complete in 600ms without janking on low-end devices.

**Mitigation**:
- CSS transforms (GPU accelerated)
- Animation level user setting (none, subtle, full)
- Performance testing on 4GB RAM devices
- Fallback to no animation if performance issues

**Testing Requirements**:
- Animation performance on low-end devices
- Frame rate validation (60fps target)

**Owner**: dev
**Timeline**: Performance optimization Sprint 2

### 9. UX-001: Audio Feedback Distraction or Annoyance

**Score: 4 (Medium)**
**Probability**: Medium (2) - Audio is subjective
**Impact**: Medium (2) - Can be disabled, not critical

**Description**: Audio feedback (pitched_tone, harmony) may annoy some students or distract in classroom environments.

**Mitigation**:
- Audio enabled by user preference (default: enabled)
- Teacher can disable for entire class
- Contextual sounds only, not decorative
- Volume control
- Mute option easily accessible

**Testing Requirements**:
- User testing with audio enabled/disabled
- Classroom environment testing
- Audio preference persistence

**Owner**: ux-expert
**Timeline**: User testing Sprint 3

### 10. REL-001: Feedback System Failure Doesn't Block Learning

**Score: 4 (Medium)**
**Probability**: Medium (2) - Systems fail
**Impact**: Medium (2) - Degraded experience but not blocking

**Description**: If feedback system fails, student must still be able to continue learning activities.

**Mitigation**:
- Graceful degradation (simple "Correct/Incorrect" fallback)
- Error boundaries around feedback rendering
- Logging for feedback failures
- No blocking of next question

**Testing Requirements**:
- Feedback failure scenarios
- Graceful degradation validation
- Error boundary testing

**Owner**: dev
**Timeline**: Sprint 1-2

## Risk Distribution

### By Category
- Pedagogical: 2 risks (1 critical, 1 high) - 15 points
- Performance: 2 risks (1 critical, 1 medium) - 13 points
- Accessibility: 1 risk (1 critical) - 9 points
- Integration: 1 risk (1 high) - 6 points
- Data/State: 1 risk (1 high) - 6 points
- User Experience: 1 risk (1 medium) - 4 points
- Reliability: 1 risk (1 medium) - 4 points
- Content Quality: 1 risk (1 high) - 6 points

### By Component
- FeedbackEngine: 5 risks (2 critical, 2 high)
- Message Bank: 2 risks (1 high)
- Visual/Animation: 2 risks (1 critical, 1 medium)
- Audio System: 1 risk (1 medium)
- Integration Layer: 1 risk (1 high)

## Risk-Based Testing Strategy

### Priority 1: Critical Risk Tests (P0)

**Pedagogical Quality (PED-001)**
- Emotional response testing with 9-12 year olds
- Forbidden words validation
- Pedagogical expert review checklist
- A/B testing framework operational

**Performance (PERF-001)**
- Feedback display <100ms validation
- Performance benchmarks on low-end devices
- Network latency testing
- Concurrent user performance

**Accessibility (ACC-001)**
- Screen reader testing (NVDA, JAWS, VoiceOver)
- WCAG 2.1 AA compliance
- Keyboard navigation
- Color contrast validation

### Priority 2: High Risk Tests (P1)

**Message Diversity (REPO-001)**
- Message rotation testing (no repeats in 10)
- Message bank coverage validation
- Long session testing (30+ interactions)

**Module Integration (INT-001)**
- Integration with M1, M5, M10, M14
- Invalid response handling
- State synchronization

**Tone Appropriateness (PED-002)**
- User testing surveys
- Cross-cultural validation
- Teacher feedback collection

**Context Preservation (DATA-001)**
- Context persistence across sessions
- Module transition tests
- Graceful degradation validation

### Priority 3: Medium Risk Tests (P2)

**Animation Performance (PERF-002)**
- Low-end device animation testing
- Frame rate validation

**Audio Experience (UX-001)**
- User testing with audio
- Preference persistence

**Failure Graceful Degradation (REL-001)**
- Feedback failure scenarios
- Error boundary validation

## Risk Acceptance Criteria

### Must Fix Before Production

1. **PED-001**: Positive emotional response validated - CRITICAL
2. **PERF-001**: <100ms feedback display verified - CRITICAL
3. **ACC-001**: WCAG AA compliance validated - CRITICAL
4. **INT-001**: Integration with all MVP modules working - HIGH

### Can Deploy with Mitigation

5. **REPO-001**: Minimum 5 message variations per category (target 10)
6. **PED-002**: Teacher feedback mechanism in place for iteration
7. **DATA-001**: Basic context working, advanced features iterative

### Accepted Risks

8. **PERF-002**: Animation degradation acceptable on very old devices
9. **UX-001**: Audio can be disabled, not blocking
10. **REL-001**: Graceful fallback acceptable for MVP

## Monitoring Requirements

Post-deployment monitoring for:

### Pedagogical Metrics
- Student engagement after receiving feedback
- Feedback interaction time
- A/B test results for message effectiveness
- Teacher reports of student reactions

### Performance Metrics
- Feedback display latency (P50, P95, P99)
- Animation frame rates
- Audio synthesis timing
- Device performance correlation

### Accessibility Metrics
- Screen reader usage patterns
- Keyboard-only navigation rates
- High contrast mode usage
- Accessibility error rates

### Content Quality Metrics
- Message repetition rates
- Message diversity scores
- Student satisfaction surveys
- Teacher customization usage

## Risk Review Triggers

Review and update risk profile when:

1. User testing reveals unexpected emotional responses
2. Performance targets not met in testing
3. New module types added beyond MVP
4. Accessibility issues reported
5. Message bank expanded or modified
6. Integration points with US-001 change
7. Student feedback indicates tone issues

## Appendix: Risk Calculation Details

**Risk Score Calculation:**
```
Base Score = 100
Critical (9): -20 points × 3 = -60
High (6): -10 points × 4 = -40
Medium (4): -5 points × 3 = -15
Total Deductions: -115
Floor at 0: max(100 - 115, 0) = 0
Adjusted for planning stage with mitigations: 42/100
```

**Note**: This is a high-risk story due to:
- Human psychology complexity (2 critical pedagogical risks)
- Aggressive performance targets (<100ms)
- Critical accessibility requirements
- Dependency on US-001 quality

Risk score will improve as mitigations are implemented and validated through user testing.

## Special Considerations for US-003

### Pedagogical Quality is Non-Negotiable

Unlike typical technical stories, US-003 has **pedagogical quality as a functional requirement**. Traditional QA focuses on "does it work?" - this story requires "does it help students learn without harm?"

**Implications**:
- User testing with 9-12 year olds is NOT optional (DoD requirement)
- Pedagogical expert review is NOT a nice-to-have
- Emotional response data is a GATE CRITERION
- No deployment without validated positive student experience

### Performance Target Justification

The <100ms target is pedagogically justified:
- Immediate feedback = behavior reinforcement (learning science)
- Delay >100ms perceived as "system thinking" not "immediate response"
- Students disengage if feedback feels slow

**However**: This is aggressive for web systems. Mitigation strategy must be robust.

### Accessibility as Core, Not Add-On

Feedback is THE core learning interaction. If inaccessible, the platform fails its mission. Accessibility testing is P0, not P2.

### US-001 Dependency Critical

US-003 integrates with EVERY module. If US-001 has instability, US-003 amplifies it across the entire platform. Gate verification mandatory.
