# Risk Profile: Story 1.M5 - Módulo IdentificaOperação

Date: 2025-10-01
Reviewer: Quinn (Test Architect)

## Executive Summary

- Total Risks Identified: 10
- Critical Risks: 3
- High Risks: 4
- Medium Risks: 3
- Risk Score: 48/100

**Status**: PLANNING - Risk assessment for implementation guidance

**Special Considerations**: This module integrates mathematics with Portuguese language arts, requires Brazilian cultural context validation, and depends on high-quality pedagogical content (70+ problems). Content quality is the primary risk area.

## Critical Risks Requiring Immediate Attention

### 1. CONTENT-001: Problem Bank Quality and Pedagogical Appropriateness

**Score: 9 (Critical)**
**Probability**: High (3) - Creating 70+ age-appropriate, culturally relevant problems is complex
**Impact**: High (3) - Poor content quality undermines educational value, student confusion, BNCC non-compliance

**Description**: The module requires a minimum of 70 problems (20 addition, 20 subtraction, 15 multiplication, 15 division) that are age-appropriate for 9-12 year olds, culturally relevant to Brazilian context, use Brazilian Portuguese vocabulary, and clearly map to single operations without ambiguity. Creating this volume of quality content is the highest risk.

**Affected Components**:
- Problem bank JSON data (problemBank array)
- Keyword effectiveness across contexts
- Cultural references validation
- Age-appropriate vocabulary
- Educational feedback quality

**Mitigation**:
- **Content Creation Process**:
  - Partner with Brazilian elementary educator for content review (REQUIRED)
  - Create content template with quality criteria checklist
  - Pilot test problems with 5-10 students (age 9-12)
  - Iterate based on comprehension testing results
- **Quality Criteria per Problem**:
  - Single correct operation (no ambiguity)
  - Age-appropriate vocabulary (verified against 4th-6th grade standards)
  - Brazilian cultural context (Real currency, local names, familiar scenarios)
  - Clear keyword presence
  - Realistic scenario from student experience
- **Validation Pipeline**:
  - Technical validation: JSON schema, keyword presence, structure
  - Pedagogical review: Age-appropriateness, clarity, BNCC alignment
  - Cultural review: Brazilian context, vocabulary, names
  - Pilot testing: Comprehension rate >80% for target difficulty

**Testing Requirements**:
- Content comprehension testing with target age group (n=10 minimum)
- Keyword recognition validation per operation type
- Cultural appropriateness review by Brazilian educator
- Problem clarity assessment (ambiguity detection)
- Difficulty progression validation (Level 1→2→3)

**Residual Risk**: Medium - Even with review, edge cases may emerge in production

**Owner**: po (content creation) + analyst (pedagogical review) + qa (validation)
**Timeline**: CRITICAL - Must complete problem bank before module implementation
**Blocking**: This is a blocking risk - no implementation should begin without validated content

---

### 2. BNCC-001: Dual Competency Alignment (Math + Portuguese)

**Score: 9 (Critical)**
**Probability**: High (3) - Integrating two BNCC competencies adds complexity
**Impact**: High (3) - Regulatory non-compliance, failure to meet learning objectives

**Description**: The module must simultaneously address EF04MA07 (mathematical problem-solving with multiplication/division) and EF04LP15 (locating explicit information in texts). Balancing both competencies without compromising either is complex.

**Affected Components**:
- Problem text complexity (Portuguese comprehension level)
- Mathematical operation difficulty
- Keyword teaching strategy
- Feedback integration (math + text interpretation)
- Analytics tracking (dual competency progress)

**Mitigation**:
- **BNCC Mapping**:
  - Create explicit mapping of each problem to both competencies
  - EF04MA07: All 4 operations represented (addition, subtraction, multiplication, division)
  - EF04LP15: Text complexity appropriate for 4th grade reading level
- **Competency Balance**:
  - Primary focus: Operation identification (EF04MA07)
  - Secondary support: Keyword recognition in text (EF04LP15)
  - Ensure text complexity doesn't overshadow math learning
- **Assessment Criteria**:
  - Track keyword recognition success rate separately
  - Track operation selection accuracy separately
  - Identify if failures are reading-based vs math-based
- **Validation**:
  - Brazilian educator reviews BNCC alignment
  - Lexile/reading level analysis for text complexity
  - Pilot testing measures both competencies independently

**Testing Requirements**:
- BNCC competency mapping validation per problem
- Reading level analysis (target: 4th grade / Lexile 600-700)
- Dual competency tracking in analytics output
- Educator review of alignment quality

**Residual Risk**: Low - With proper mapping and educator review

**Owner**: po (BNCC mapping) + analyst (validation)
**Timeline**: Must complete before content creation begins
**Blocking**: Medium priority blocker

---

### 3. KEYWORD-001: Keyword Strategy Effectiveness Across Contexts

**Score: 9 (Critical)**
**Probability**: High (3) - Keywords may not be universally recognized by students
**Impact**: High (3) - Students fail to identify operations, learning objective not met

**Description**: The module's pedagogical strategy relies on students recognizing keywords (ganhou→addition, perdeu→subtraction, cada→multiplication, repartir→division). If keywords are not familiar to students' vocabulary, or if contexts create ambiguity, the strategy fails.

**Affected Components**:
- Keyword selection for each operation
- Problem wording (keyword context)
- Educational feedback (keyword explanation)
- Progressive keyword introduction (Level 1→2→3)
- Regional vocabulary variations (Brazilian Portuguese dialects)

**Mitigation**:
- **Keyword Validation**:
  - Validate keyword familiarity with target age group (survey n=20+)
  - Test keyword recognition rates per operation type
  - Create keyword frequency analysis (most to least common)
- **Progressive Introduction**:
  - Level 1: Single dominant keyword (ganhou, perdeu, cada, repartir)
  - Level 2: Multiple keywords, one dominant
  - Level 3: Contextual understanding beyond keywords
- **Regional Considerations**:
  - Use vocabulary common across Brazil (avoid regionalisms)
  - Provide keyword glossary if needed
  - Test with students from different regions
- **Ambiguity Detection**:
  - Review all problems for unintended keywords
  - Ensure distractor explanations address confusion
  - Pilot test ambiguous scenarios

**Testing Requirements**:
- Keyword familiarity survey (target age group, n=20+)
- Keyword recognition accuracy testing per operation
- Regional vocabulary validation (multiple Brazilian regions)
- Ambiguity detection testing (false positive keywords)
- Progressive difficulty validation (Level 1: 90%+ success, Level 2: 75%+, Level 3: 60%+)

**Residual Risk**: Medium - Regional variations may still cause confusion

**Owner**: po (keyword selection) + analyst (validation) + ux-expert (feedback design)
**Timeline**: CRITICAL - Must validate keywords before problem creation
**Blocking**: High priority blocker - affects all content

---

## High Risks

### 4. CONTENT-002: Cultural Context and Brazilian Relevance

**Score: 6 (High)**
**Probability**: Medium (2) - Cultural misalignment possible without local expertise
**Impact**: High (3) - Students disengage, content feels foreign, reduced learning effectiveness

**Description**: Problems must use Brazilian cultural references (Real currency, local names, familiar contexts) to maximize student engagement and comprehension. Without Brazilian educator input, content may feel generic or culturally misaligned.

**Mitigation**:
- Use Brazilian names (gender-neutral when possible): Ana, João, Pedro, Maria, Carlos, Lucas
- Use Brazilian contexts: school supplies, lunch (merenda), popular sports (futebol)
- Use Brazilian currency (Real, R$)
- Avoid North American or European references
- Brazilian educator reviews all content for cultural appropriateness
- Pilot testing includes cultural relevance feedback

**Testing Requirements**:
- Cultural appropriateness checklist per problem
- Brazilian educator sign-off
- Student feedback on relatability (pilot testing)

**Owner**: po (content) + analyst (cultural review)
**Timeline**: During content creation phase

---

### 5. ACCESS-001: Accessibility for Students with Reading Difficulties

**Score: 6 (High)**
**Probability**: Medium (2) - Dual demand (reading + math) creates accessibility barriers
**Impact**: High (3) - Excludes students with dyslexia, slow readers, or reading delays

**Description**: The module requires simultaneous reading comprehension and mathematical reasoning. Students with reading difficulties may struggle not because of math ability, but due to text access barriers.

**Mitigation**:
- Use Atkinson Hyperlegible font (18px minimum) for readability
- Provide audio narration option for problem text (future enhancement)
- Keyword highlighting to guide attention
- Simple sentence structures (max 2 clauses)
- Allow unlimited time for reading (no timer on text comprehension)
- Consider text-to-speech integration (WCAG 2.1 AA)
- Screen reader compatibility for visually impaired students

**Testing Requirements**:
- Screen reader testing (NVDA, JAWS)
- Keyboard navigation testing
- Text complexity analysis (Flesch-Kincaid, Lexile)
- Testing with students who have reading accommodations
- WCAG 2.1 AA compliance verification

**Owner**: ux-expert (accessibility design) + dev (implementation) + qa (testing)
**Timeline**: Design phase, implementation, pre-launch testing

---

### 6. DATA-003: Problem Bank Content Versioning and Updates

**Score: 6 (High)**
**Probability**: Medium (2) - Content will need updates based on feedback
**Impact**: High (3) - Inconsistent content across versions, breaking changes

**Description**: After launch, pilot testing will reveal problem quality issues, ambiguities, or cultural misalignments. Updating problem bank content requires versioning to prevent breaking existing teacher activities.

**Mitigation**:
- Include `problemBankVersion` field in module configuration
- Problem bank updates don't break existing activities
- Migration strategy for problem bank schema changes
- Track which problems are most/least effective (analytics)
- Create problem bank update workflow (review → approve → deploy)
- Archive deprecated problems (don't delete)

**Testing Requirements**:
- Problem bank version compatibility testing
- Migration testing for schema updates
- Backward compatibility validation

**Owner**: dev (versioning architecture) + po (content updates)
**Timeline**: Design phase (versioning strategy)

---

### 7. FEEDBACK-001: Educational Feedback Quality and Clarity

**Score: 6 (High)**
**Probability**: Medium (2) - Feedback must be pedagogically sound and age-appropriate
**Impact**: High (3) - Poor feedback reduces learning effectiveness

**Description**: When students select incorrect operations, feedback must explain why they're wrong AND why the correct operation is right, using age-appropriate language and keyword connections.

**Mitigation**:
- Create feedback templates reviewed by Brazilian educator
- Use positive, encouraging language
- Connect feedback to keywords explicitly: "João GANHOU maçãs, então somamos"
- Provide distractor explanations for each wrong choice
- Test feedback clarity with students (comprehension check)
- Avoid technical math jargon
- Keep feedback concise (1-2 sentences)

**Testing Requirements**:
- Feedback comprehension testing with target age group
- Educator review of pedagogical quality
- Clarity assessment (student feedback)

**Owner**: po (feedback content) + analyst (pedagogical review) + ux-expert (tone/language)
**Timeline**: During content creation

---

## Medium Risks

### 8. UI-001: Keyword Highlighting Distraction and Cognitive Load

**Score: 4 (Medium)**
**Probability**: Medium (2) - Highlighting can help or distract depending on design
**Impact**: Medium (2) - Overwhelming UI reduces focus, students miss keywords

**Description**: The module highlights keywords to guide attention, but over-highlighting or visually distracting effects could increase cognitive load and reduce effectiveness.

**Mitigation**:
- Subtle highlighting: underline or bold (not bright colors)
- Progressive highlighting: fade in after 2 seconds (gives students time to read first)
- User control: toggle keyword highlighting on/off (accessibility)
- Test with students: measure if highlighting helps or distracts
- A/B testing: highlighted vs non-highlighted groups

**Testing Requirements**:
- User testing with/without keyword highlighting
- Cognitive load assessment (time to read, comprehension)
- A/B testing for effectiveness

**Owner**: ux-expert (design) + qa (user testing)
**Timeline**: Prototype testing phase

---

### 9. PERF-003: Problem Bank Size and Load Performance

**Score: 4 (Medium)**
**Probability**: Medium (2) - 70+ problems with full metadata = large JSON
**Impact**: Medium (2) - Slow module initialization, poor UX on slow networks

**Description**: The problem bank JSON with 70+ problems, keywords, explanations, and distractor text could be large (estimated 50-100KB). Loading all problems upfront may slow module initialization.

**Mitigation**:
- Lazy loading: load 10 problems at a time (only what's needed for current session)
- Problem bank compression (gzip)
- Cache problem bank in localStorage after first load
- Bundle size budget: problem bank <50KB compressed
- Progress indicator during load

**Testing Requirements**:
- Bundle size analysis (problem bank JSON size)
- Load performance testing on 3G network
- Caching validation (second load <500ms)

**Owner**: dev (optimization) + qa (performance testing)
**Timeline**: Implementation phase

---

### 10. ANALYTICS-001: Data Collection Accuracy for Keyword Recognition

**Score: 4 (Medium)**
**Probability**: Medium (2) - Complex analytics structure with per-keyword tracking
**Impact**: Medium (2) - Inaccurate data leads to wrong pedagogical conclusions

**Description**: The module tracks keyword recognition rates per keyword (ganhou: 100%, repartir: 50%). If tracking is inaccurate, teachers won't know which keywords are problematic.

**Mitigation**:
- Validate analytics schema against data output
- Test analytics with sample sessions (known correct/incorrect patterns)
- Ensure keyword recognition tracked correctly (not just operation accuracy)
- Provide analytics validation dashboard for QA
- Cross-check analytics with session replay (if available)

**Testing Requirements**:
- Analytics schema validation
- Sample session testing (verify output matches expected)
- Keyword tracking accuracy verification

**Owner**: dev (analytics implementation) + qa (validation)
**Timeline**: Implementation phase

---

## Risk Distribution

### By Category
- Content Quality: 3 risks (2 critical) - 24 points
- BNCC/Pedagogical: 1 risk (1 critical) - 9 points
- Accessibility: 1 risk (0 critical) - 6 points
- Data/Technical: 2 risks (0 critical) - 10 points
- UX/Feedback: 2 risks (0 critical) - 10 points
- Performance: 1 risk (0 critical) - 4 points

### By Component
- Problem Bank Content: 4 risks (2 critical)
- Keyword Strategy: 2 risks (1 critical)
- Educational Feedback: 1 risk (0 critical)
- Accessibility: 1 risk (0 critical)
- Analytics: 1 risk (0 critical)
- UI/UX: 1 risk (0 critical)

## Risk-Based Testing Strategy

### Priority 1: Critical Risk Tests (P0)

**Content Quality (CONTENT-001)**
- Problem comprehension testing with target age group (n=10+)
- Ambiguity detection testing (all 70 problems reviewed)
- Cultural appropriateness validation (Brazilian educator sign-off)
- Age-appropriate vocabulary verification

**BNCC Alignment (BNCC-001)**
- Dual competency mapping validation (all problems)
- Reading level analysis (Lexile/Flesch-Kincaid)
- Educator BNCC alignment review

**Keyword Effectiveness (KEYWORD-001)**
- Keyword familiarity survey (n=20+)
- Keyword recognition accuracy testing per operation
- Progressive difficulty validation (Level 1: 90%+, Level 2: 75%+, Level 3: 60%+)

### Priority 2: High Risk Tests (P1)

**Cultural Context (CONTENT-002)**
- Cultural relevance review by Brazilian educator
- Student pilot testing with cultural feedback

**Accessibility (ACCESS-001)**
- Screen reader testing (NVDA, JAWS)
- WCAG 2.1 AA compliance audit
- Text complexity analysis

**Content Versioning (DATA-003)**
- Problem bank version compatibility testing
- Migration validation

**Feedback Quality (FEEDBACK-001)**
- Feedback comprehension testing with students
- Educator pedagogical review

### Priority 3: Medium Risk Tests (P2)

**UI Highlighting (UI-001)**
- User testing with/without keyword highlighting
- Cognitive load assessment

**Performance (PERF-003)**
- Load performance testing on 3G
- Bundle size validation

**Analytics (ANALYTICS-001)**
- Analytics output validation
- Keyword tracking accuracy verification

---

## Risk Acceptance Criteria

### Must Fix Before Production

1. **CONTENT-001**: 70+ quality problems validated by Brazilian educator - CRITICAL
2. **BNCC-001**: Dual competency alignment documented and validated - CRITICAL
3. **KEYWORD-001**: Keyword effectiveness validated with target age group - CRITICAL
4. **ACCESS-001**: WCAG 2.1 AA compliance verified - HIGH

### Can Deploy with Mitigation

5. **CONTENT-002**: Cultural review completed (acceptable if 80%+ students find relevant)
6. **DATA-003**: Versioning strategy in place (v1 only for MVP)
7. **FEEDBACK-001**: Feedback clarity validated (acceptable if 75%+ comprehension)

### Accepted Risks

8. **UI-001**: Keyword highlighting (ship with default, iterate based on feedback)
9. **PERF-003**: Load performance (acceptable if <3s on 3G)
10. **ANALYTICS-001**: Analytics accuracy (acceptable if 90%+ accuracy)

---

## Monitoring Requirements

Post-deployment monitoring for:

### Content Quality Metrics
- Problem completion rate per problem (identify confusing problems)
- Incorrect selection patterns (identify ambiguous keywords)
- Student feedback on problem clarity
- Time spent per problem (outliers indicate confusion)

### Pedagogical Effectiveness
- Keyword recognition improvement over time
- Operation accuracy improvement across sessions
- Concepts struggling by operation type
- Dual competency progress (math vs reading)

### Accessibility Metrics
- Screen reader usage tracking
- Keyboard-only interaction tracking
- Average reading time (identify slow readers needing support)

### Business KPIs
- Module completion rates
- Teacher satisfaction with problem quality
- Student engagement (repeat usage)
- Support tickets for problem clarity issues

---

## Risk Review Triggers

Review and update risk profile when:

1. Pilot testing reveals problem quality issues
2. Brazilian educator identifies cultural misalignments
3. Keyword recognition rates below 70% for any operation type
4. BNCC alignment concerns raised
5. Accessibility complaints received
6. Problem bank content updated (versioning changes)
7. New difficulty levels added beyond MVP (Level 4+)

---

## Special Considerations for US-M5

### Integration with US-001 Runtime System
- **Dependency**: US-M5 depends on US-001 (Sistema Runtime de Módulos) being stable
- **Risk**: If US-001 has issues, US-M5 will amplify them
- **Mitigation**: Verify US-001 quality gate is PASS before implementing US-M5

### Integration with US-003 Feedback System
- **Dependency**: US-M5 educational feedback integrates with US-003 (Feedback Formativo)
- **Risk**: Feedback quality depends on US-003 implementation
- **Mitigation**: Define feedback interface contract early, test with mock feedback system

### Brazilian Educator Partnership (CRITICAL)
- **Requirement**: This module CANNOT ship without Brazilian elementary educator review
- **Rationale**: Cultural context, BNCC alignment, age-appropriateness require local expertise
- **Action**: Identify and onboard Brazilian educator partner before content creation begins
- **Estimated Time**: 10-15 hours educator time (content review, BNCC mapping, pilot testing)

---

## Appendix: Risk Calculation Details

**Risk Score Calculation:**
```
Base Score = 100
Critical (9): -20 points × 3 = -60
High (6): -10 points × 4 = -40
Medium (4): -5 points × 3 = -15
Total Deductions: -115
Floor at 0: max(100 - 115, 0) = 0
Adjusted for planning stage with mitigations: 48/100
```

**Risk Score Interpretation:**
- 48/100 = HIGH RISK but ACCEPTABLE WITH MITIGATIONS
- Content quality risks dominate
- Brazilian educator partnership is critical success factor
- MVP can ship if critical risks mitigated

**Note**: Risk score will be recalculated during implementation review based on actual content quality validation results.

---

## Recommended Risk Mitigation Timeline

### Phase 1: Pre-Development (Week 1-2)
1. Onboard Brazilian elementary educator partner
2. Validate keyword familiarity with target age group (survey n=20+)
3. Create BNCC dual competency mapping template
4. Define content quality criteria checklist

### Phase 2: Content Creation (Week 3-4)
1. Create 70+ problems using template
2. Technical validation (JSON schema, keyword presence)
3. Brazilian educator reviews all problems
4. Iterate based on educator feedback

### Phase 3: Validation (Week 5)
1. Pilot testing with 10-15 students (age 9-12)
2. Measure comprehension rates, keyword recognition
3. Identify ambiguous problems
4. Iterate content based on pilot results

### Phase 4: Implementation (Week 6-8)
1. Implement module with validated content
2. Accessibility testing (screen reader, keyboard)
3. Performance testing (load time, bundle size)
4. Analytics validation

### Phase 5: Launch Readiness (Week 9)
1. Final Brazilian educator sign-off
2. BNCC alignment verification
3. WCAG 2.1 AA compliance audit
4. Gate review (all critical risks mitigated)

**Total Timeline**: ~9 weeks (content quality is the long pole)

---

**QA Contact**: For questions about this risk profile, contact Quinn (Test Architect).

**Critical Success Factor**: Brazilian educator partnership is non-negotiable for this module's success.
