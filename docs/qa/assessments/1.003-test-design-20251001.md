# Test Design: Story 1.003 - Sistema de Feedback Formativo

Date: 2025-10-01
Designer: Quinn (Test Architect)

## Test Strategy Overview

- **Total test scenarios**: 42
- **Unit tests**: 15 (36%)
- **Integration tests**: 14 (33%)
- **E2E tests**: 5 (12%)
- **User testing**: 5 (12%)
- **Accessibility tests**: 3 (7%)
- **Priority distribution**: P0: 22, P1: 15, P2: 5

**Approach**: Comprehensive strategy balancing technical validation with human-centered testing. User testing with 9-12 year olds is MANDATORY (DoD requirement) and gates deployment.

**Special Considerations**:
- **Pedagogical quality testing** is as critical as functional testing
- **Performance <100ms** requires dedicated performance test suite
- **Accessibility** is P0, not P2 (educational equity)
- **Emotional impact** must be validated with target demographic

---

## Test Scenarios by Acceptance Criteria

### AC-1: Immediate Response Feedback

#### Scenarios

| ID | Level | Priority | Test Scenario | Justification |
|---|---|---|---|---|
| 1.003-UNIT-001 | Unit | P0 | Feedback display <100ms after submission | Core performance requirement |
| 1.003-UNIT-002 | Unit | P0 | Visual feedback includes semantic colors | Accessibility + UX |
| 1.003-UNIT-003 | Unit | P0 | Correct answer shows ✓ green | Visual feedback validation |
| 1.003-UNIT-004 | Unit | P0 | Incorrect answer shows ✗ red | Visual feedback validation |
| 1.003-UNIT-005 | Unit | P1 | No harsh sounds in audio feedback | Pedagogical principle (P2) |
| 1.003-UNIT-006 | Unit | P1 | No punitive animations | Pedagogical principle (P2) |
| 1.003-UNIT-007 | Unit | P0 | Encouragement message regardless of correctness | Psychological safety |
| 1.003-INT-001 | Integration | P0 | Feedback integrated with M1 (BateriaRápida) | MVP module integration |
| 1.003-INT-002 | Integration | P0 | Feedback integrated with M5 (IdentificaOperação) | MVP module integration |
| 1.003-INT-003 | Integration | P0 | Feedback integrated with M10 (JeremiasResolver) | MVP module integration |
| 1.003-INT-004 | Integration | P0 | Feedback integrated with M14 (AutoAvaliação) | MVP module integration |
| 1.003-PERF-001 | Performance | P0 | Feedback display P95 latency <100ms | Performance gate criterion |
| 1.003-PERF-002 | Performance | P0 | 30 consecutive feedback <100ms each | BateriaRápida stress test |
| 1.003-E2E-001 | E2E | P1 | Student completes activity with feedback | End-to-end validation |

**Coverage**: AC-1 fully covered with 14 scenarios

**Risk Mitigations**:
- PERF-001 (100ms target) → UNIT-001, PERF-001, PERF-002
- INT-001 (module integration) → INT-001/002/003/004
- PED-001 (inappropriate feedback) → UNIT-005, UNIT-006, UNIT-007

---

### AC-2: Constructive Explanation (Incorrect Response)

#### Scenarios

| ID | Level | Priority | Test Scenario | Justification |
|---|---|---|---|---|
| 1.003-UNIT-008 | Unit | P0 | Explanation language is 9-12 year old appropriate | Pedagogical quality |
| 1.003-UNIT-009 | Unit | P0 | Explanation focuses on learning, not failure | P2 principle validation |
| 1.003-UNIT-010 | Unit | P0 | No forbidden words in explanation ("wrong", "failed", "bad") | Automated quality check |
| 1.003-UNIT-011 | Unit | P1 | Explanation provides specific guidance | Pedagogical effectiveness |
| 1.003-USER-001 | User Testing | P0 | Students understand what to do next (>90%) | Comprehension validation |
| 1.003-USER-002 | User Testing | P0 | Students feel encouraged, not punished (>80%) | Emotional response |
| 1.003-USER-003 | User Testing | P0 | Tone perceived as age-appropriate (not condescending) | PED-002 mitigation |
| 1.003-INT-005 | Integration | P1 | Message bank has minimum 10 variations per category | REPO-001 mitigation |
| 1.003-INT-006 | Integration | P1 | Message rotation (no repeat in 10 interactions) | Diversity validation |

**Coverage**: AC-2 fully covered with 9 scenarios (3 user testing)

**Risk Mitigations**:
- PED-001 (inappropriate language) → USER-002, UNIT-010
- PED-002 (condescending tone) → USER-003
- REPO-001 (repetition) → INT-005, INT-006

---

### AC-3: Positive Reinforcement (Correct Response)

#### Scenarios

| ID | Level | Priority | Test Scenario | Justification |
|---|---|---|---|---|
| 1.003-UNIT-012 | Unit | P0 | Positive acknowledgment of success | Behavioral reinforcement |
| 1.003-UNIT-013 | Unit | P0 | Brief reinforcement of concept | Learning consolidation |
| 1.003-UNIT-014 | Unit | P0 | Encouragement for next challenge | Engagement maintenance |
| 1.003-UNIT-015 | Unit | P1 | No "over-the-top" celebration (P4: Economy of Attention) | Anti-distraction |
| 1.003-USER-004 | User Testing | P1 | Students remain engaged after success | Engagement validation |
| 1.003-INT-007 | Integration | P1 | Celebration animation <600ms, non-distracting | Animation timing + UX |

**Coverage**: AC-3 fully covered with 6 scenarios (1 user testing)

**Risk Mitigations**:
- UX-001 (distraction) → UNIT-015, INT-007

---

### AC-4: Accessibility (Added based on NFR)

#### Scenarios

| ID | Level | Priority | Test Scenario | Justification |
|---|---|---|---|---|
| 1.003-ACC-001 | Accessibility | P0 | Screen reader announces feedback (NVDA) | WCAG AA + educational equity |
| 1.003-ACC-002 | Accessibility | P0 | Screen reader announces feedback (JAWS) | Multi-SR validation |
| 1.003-ACC-003 | Accessibility | P0 | Screen reader announces feedback (VoiceOver) | Mac/iOS support |
| 1.003-INT-008 | Integration | P0 | ARIA live region updates correctly | Technical implementation |
| 1.003-INT-009 | Integration | P0 | Color contrast 4.5:1 minimum | WCAG AA compliance |
| 1.003-INT-010 | Integration | P0 | Color + icon + text (not color alone) | Accessibility best practice |
| 1.003-INT-011 | Integration | P1 | Keyboard navigation (Esc to dismiss, Space to replay) | Keyboard-only users |
| 1.003-INT-012 | Integration | P1 | High contrast mode support | Visual accessibility |
| 1.003-E2E-002 | E2E | P1 | Keyboard-only user completes activity | Accessibility journey |

**Coverage**: AC-4 (accessibility) fully covered with 9 scenarios

**Risk Mitigations**:
- ACC-001 (screen reader failures) → ACC-001/002/003, INT-008

---

## Performance & Non-Functional Tests

| ID | Level | Priority | Test Scenario | Target | Justification |
|---|---|---|---|---|---|
| 1.003-PERF-001 | Performance | P0 | Feedback display latency P50/P95/P99 | <100ms | Gate criterion |
| 1.003-PERF-002 | Performance | P0 | 30 consecutive feedback displays | <100ms each | BateriaRápida scenario |
| 1.003-PERF-003 | Performance | P0 | Message selection algorithm timing | <30ms | Component budget |
| 1.003-PERF-004 | Performance | P0 | Animation setup timing | <20ms | Component budget |
| 1.003-PERF-005 | Performance | P0 | Audio synthesis timing | <20ms | Component budget |
| 1.003-PERF-006 | Performance | P0 | ARIA update timing | <15ms | Component budget |
| 1.003-PERF-007 | Performance | P1 | Low-end device performance (2GB RAM) | <120ms acceptable | Device variability |
| 1.003-PERF-008 | Performance | P1 | Animation frame rate | 60fps | Smooth UX |
| 1.003-PERF-009 | Performance | P2 | Network latency resilience (200ms RTT) | Graceful | Connectivity |

**Coverage**: All performance requirements testable with component-level budgets

**Risk Mitigations**:
- PERF-001 (100ms target) → PERF-001/002/003/004/005/006
- PERF-002 (animation performance) → PERF-008

---

## Pedagogical Quality Tests (User Testing)

| ID | Level | Priority | Test Scenario | Success Criteria | Justification |
|---|---|---|---|---|---|
| 1.003-USER-001 | User Testing | P0 | Comprehension testing | >90% understand next steps | Pedagogical effectiveness |
| 1.003-USER-002 | User Testing | P0 | Emotional response survey | >80% positive reactions | PED-001 gate criterion |
| 1.003-USER-003 | User Testing | P0 | Tone appropriateness survey | <20% "too childish/grown-up" | PED-002 validation |
| 1.003-USER-004 | User Testing | P1 | Engagement after success | Continue to next challenge | Motivation validation |
| 1.003-USER-005 | User Testing | P1 | Engagement after mistakes | Try again without frustration | Psychological safety |

**User Testing Protocol**:
- **Participants**: 12-18 students aged 9-12 (diverse socioeconomic backgrounds)
- **Session duration**: 20 minutes (activity with feedback)
- **Data collection**:
  - Pre-session: Demographic, baseline attitude toward math/Portuguese
  - During session: Observation (facial expressions, body language, comments)
  - Post-session: Survey (emotional response, comprehension, tone perception)
  - Follow-up: Teacher interviews (engagement, behavior changes)

**Survey Questions**:
1. "How did the feedback make you feel?" (5-point scale: Very Bad → Very Good)
2. "Did you understand what to do next?" (Yes/No/Sometimes)
3. "Was the feedback too childish, too grown-up, or just right?" (3-point scale)
4. "Did you want to keep trying after making mistakes?" (Yes/No/Sometimes)
5. "Would you use this activity again?" (Yes/No/Maybe)

**Risk Mitigations**:
- PED-001 (emotional harm) → USER-002 (mandatory gate)
- PED-002 (condescending tone) → USER-003
- REPO-001 (disengagement) → USER-004, USER-005

---

## Risk Coverage Matrix

| Risk ID | Score | Related Test Scenarios | Coverage |
|---|---|---|---|
| PED-001 | 9 | USER-002, UNIT-010, USER-003 | ✓ Full |
| PERF-001 | 9 | PERF-001/002/003/004/005/006, UNIT-001 | ✓ Full |
| ACC-001 | 9 | ACC-001/002/003, INT-008/009/010/011 | ✓ Full |
| REPO-001 | 6 | INT-005, INT-006, USER-004, USER-005 | ✓ Full |
| INT-001 | 6 | INT-001/002/003/004 | ✓ Full |
| PED-002 | 6 | USER-003, USER-002 | ✓ Full |
| DATA-001 | 6 | INT-013, INT-014, E2E-003 | ✓ Full |
| PERF-002 | 4 | PERF-008, INT-007 | ✓ Full |
| UX-001 | 4 | UNIT-005, INT-007, USER-004 | ✓ Full |
| REL-001 | 4 | INT-015, E2E-004 | ✓ Full |

**All risks have explicit test coverage mapped**

---

## Additional Integration & E2E Tests

| ID | Level | Priority | Test Scenario | Justification |
|---|---|---|---|---|
| 1.003-INT-013 | Integration | P1 | Context preservation across sessions | DATA-001 mitigation |
| 1.003-INT-014 | Integration | P1 | Context preservation across module transitions | DATA-001 mitigation |
| 1.003-INT-015 | Integration | P1 | Feedback failure doesn't block learning | REL-001 mitigation |
| 1.003-E2E-003 | E2E | P1 | Student completes 30-problem BateriaRápida with feedback | Long session validation |
| 1.003-E2E-004 | E2E | P2 | Feedback system failure graceful degradation | Reliability journey |
| 1.003-E2E-005 | E2E | P2 | Teacher configures feedback style | Configuration validation |

---

## Test Implementation Priority

### Phase 1: P0 Tests (Critical - Block Release)

**Estimated effort: ~60 hours**

**Unit Tests** (8-10 hours):
- 1.003-UNIT-001: Feedback <100ms
- 1.003-UNIT-002/003/004: Visual feedback
- 1.003-UNIT-007: Encouragement message
- 1.003-UNIT-008/009/010: Language validation
- 1.003-UNIT-012/013/014: Positive reinforcement

**Performance Tests** (12-16 hours):
- 1.003-PERF-001: P50/P95/P99 latency
- 1.003-PERF-002: 30 consecutive feedback
- 1.003-PERF-003/004/005/006: Component budgets

**Integration Tests** (12-16 hours):
- 1.003-INT-001/002/003/004: Module integration (M1, M5, M10, M14)
- 1.003-INT-008: ARIA live regions
- 1.003-INT-009/010: Color contrast + accessibility

**Accessibility Tests** (8-12 hours):
- 1.003-ACC-001/002/003: Screen reader testing (NVDA, JAWS, VoiceOver)

**User Testing** (20-24 hours):
- 1.003-USER-001: Comprehension testing (>90%)
- 1.003-USER-002: Emotional response (>80% positive) - **GATE BLOCKER**
- 1.003-USER-003: Tone appropriateness

---

### Phase 2: P1 Tests (Important - Ship with Known Gaps)

**Estimated effort: ~30 hours**

**Unit Tests** (4-6 hours):
- 1.003-UNIT-005/006: No harsh sounds/punitive animations
- 1.003-UNIT-011: Specific guidance
- 1.003-UNIT-015: No over-the-top celebration

**Integration Tests** (8-10 hours):
- 1.003-INT-005/006: Message bank diversity
- 1.003-INT-007: Animation timing
- 1.003-INT-011/012: Keyboard navigation + high contrast
- 1.003-INT-013/014: Context preservation

**Performance Tests** (4-6 hours):
- 1.003-PERF-007: Low-end device testing
- 1.003-PERF-008: Animation frame rate

**User Testing** (8-10 hours):
- 1.003-USER-004: Engagement after success
- 1.003-USER-005: Engagement after mistakes

**E2E Tests** (6-8 hours):
- 1.003-E2E-001: Student completes activity
- 1.003-E2E-002: Keyboard-only user journey
- 1.003-E2E-003: 30-problem session

---

### Phase 3: P2 Tests (Nice to Have - Future Optimization)

**Estimated effort: ~10 hours**

**Performance Tests** (2-3 hours):
- 1.003-PERF-009: Network latency resilience

**E2E Tests** (4-6 hours):
- 1.003-E2E-004: Graceful degradation journey
- 1.003-E2E-005: Teacher configuration

**Integration Tests** (2-3 hours):
- 1.003-INT-015: Feedback failure non-blocking

---

## Test Data Requirements

### Valid Feedback Scenarios

**Mathematics - Correct Responses**:
```json
{
  "response": { "answer": 5, "question": "15 ÷ 3 = ?" },
  "correctAnswer": 5,
  "concept": "division",
  "difficulty": "intermediate",
  "expectedFeedback": {
    "isCorrect": true,
    "message": {
      "primary": "Muito bem!",
      "explanation": "15 ÷ 3 = 5 porque 5 grupos de 3 fazem 15.",
      "encouragement": "Continue assim!"
    },
    "visual": {
      "color": "semantic.correct",
      "animation": "subtle-glow",
      "duration": 600
    }
  }
}
```

**Mathematics - Incorrect Responses**:
```json
{
  "response": { "answer": 4, "question": "15 ÷ 3 = ?" },
  "correctAnswer": 5,
  "concept": "division",
  "difficulty": "intermediate",
  "expectedFeedback": {
    "isCorrect": false,
    "message": {
      "primary": "Vamos pensar juntos:",
      "explanation": "Quando dividimos, estamos fazendo grupos iguais. Quantos grupos de 3 cabem em 15?",
      "encouragement": "Você consegue!"
    },
    "visual": {
      "color": "semantic.incorrect",
      "animation": "gentle-shake",
      "duration": 400
    }
  }
}
```

**Text Interpretation - Correct**:
```json
{
  "response": { "operation": "addition", "problem": "João ganhou 3 maçãs..." },
  "correctAnswer": "addition",
  "concept": "text_interpretation",
  "difficulty": "basic",
  "expectedFeedback": {
    "isCorrect": true,
    "message": {
      "primary": "Excelente!",
      "explanation": "Você identificou que João 'ganhou' maçãs, então precisamos somar.",
      "encouragement": "Ótima interpretação!"
    }
  }
}
```

**Text Interpretation - Incorrect**:
```json
{
  "response": { "operation": "subtraction", "problem": "João ganhou 3 maçãs..." },
  "correctAnswer": "addition",
  "concept": "text_interpretation",
  "difficulty": "basic",
  "expectedFeedback": {
    "isCorrect": false,
    "message": {
      "primary": "Não é bem assim.",
      "explanation": "Quando alguém 'ganha' algo, significa que tem mais do que antes. Que operação fazemos quando queremos mais?",
      "encouragement": "Pense na palavra 'ganhou'."
    }
  }
}
```

### Forbidden Words List (Automated Check)

**Never Use**:
- "wrong", "errado", "incorreto"
- "failed", "falhou", "fracassou"
- "bad", "ruim", "mal"
- "stupid", "burro", "idiota"
- "try harder", "se esforce mais"
- "that's wrong", "está errado"
- "you should know", "você deveria saber"
- "too easy for you", "fácil demais para você"
- "even a child could do this", "até criança consegue"

**Prefer Instead**:
- "Let's think together", "Vamos pensar juntos"
- "Not quite", "Não é bem assim"
- "You're on the right track", "Você está no caminho certo"
- "Good effort", "Boa tentativa"
- "Keep going", "Continue"
- Specific concept guidance (not generic encouragement)

---

## Mock/Stub Strategy

### Unit Test Mocks

**FeedbackEngine mocks**:
- Mock message bank (JSON structure)
- Stub animation system (no actual DOM manipulation)
- Stub audio synthesis (Tone.js not loaded)
- Mock concept_mastery data (student context)

**Message selection mocks**:
- Mock student history (last 10 interactions)
- Stub message rotation algorithm
- Mock A/B test configuration

### Integration Test Mocks

**Minimal mocking** (real components preferred):
- Mock only external services (analytics, logging)
- Stub Supabase for student context
- Use real FeedbackEngine with test message bank
- Use real animations (validate timing)

### E2E Test Mocks

**No mocking** (real system):
- Real FeedbackEngine
- Real message bank (test data)
- Real animations
- Real audio (if enabled)
- Mock only: Backend APIs (Supabase read/write)

---

## Test Environment Requirements

### Unit Tests
- **Framework**: Vitest (fast, Vite-aligned)
- **Assertion**: Expect API (built-in)
- **Mocking**: vi.mock (built-in)
- **Coverage**: c8 (built-in)
- **Performance**: Benchmark mode for <100ms validation

### Integration Tests
- **Framework**: Vitest + React Testing Library
- **Rendering**: @testing-library/react
- **User events**: @testing-library/user-event
- **Assertions**: @testing-library/jest-dom
- **Accessibility**: @testing-library/jest-dom/extend-expect

### E2E Tests
- **Framework**: Playwright
- **Browsers**: Chromium, Firefox, WebKit
- **Viewports**: Desktop (1920x1080), Tablet (1024x768)
- **Network**: Fast 3G, Slow 3G
- **Accessibility**: Playwright Accessibility API

### Performance Tests
- **Profiling**: React DevTools Profiler
- **Timing**: Performance API (mark/measure)
- **Monitoring**: Real User Monitoring (RUM) integration
- **Regression**: Benchmark history tracking

### Accessibility Tests
- **Screen readers**:
  - NVDA (Windows) - free, open source
  - JAWS (Windows) - requires license
  - VoiceOver (Mac/iOS) - built-in
- **Automated testing**: axe-core integration
- **Manual testing**: Keyboard navigation checklist
- **Color contrast**: axe DevTools, WAVE

### User Testing
- **Recruitment**: Partner schools (4º-6º ano classes)
- **Sessions**: 20-minute supervised sessions
- **Recording**: Observation notes, video (with consent)
- **Surveys**: Google Forms (anonymous)
- **Analysis**: Quantitative (survey %) + Qualitative (observation)

---

## Continuous Integration Strategy

### Pre-commit Hooks
- ESLint + Prettier
- Type checking (TypeScript)
- Forbidden words check (automated)
- Unit tests for changed files

### PR Pipeline
1. **Fast checks** (~3 min):
   - Lint
   - Type check
   - Unit tests (all)
   - Forbidden words validation
2. **Integration tests** (~8 min):
   - Module integration (M1, M5, M10, M14)
   - Accessibility (automated axe-core)
   - Performance benchmarks
3. **Performance validation** (~5 min):
   - <100ms latency tests
   - Component budget validation
   - Animation performance
4. **Build verification** (~2 min):
   - Production build
   - Bundle size check

### Main Branch Pipeline
- All PR checks +
- E2E tests (~15 min)
- Accessibility testing (screen readers - manual trigger)
- User testing (manual, scheduled sessions)
- Coverage report (Codecov)

---

## Test Quality Metrics

### Coverage Targets

**Overall**: 90%+ (per DoD)

**By Component**:
- FeedbackEngine: 95%+ (core logic)
- Message bank validation: 100% (quality critical)
- Animation system: 85%+ (visual/DOM heavy)
- Audio system: 85%+ (Tone.js integration)

**By Type**:
- Statements: 90%+
- Branches: 85%+
- Functions: 90%+
- Lines: 90%+

### Performance Targets

**Test execution time**:
- Unit tests: <8 seconds (all)
- Integration tests: <45 seconds (all)
- E2E tests: <3 minutes (all)
- Performance tests: <2 minutes (all)

**User testing**:
- Session duration: 20 minutes per student
- Total participants: 12-18 students
- Success criteria: >80% positive emotional response (GATE BLOCKER)

### Quality Gates

**Automated checks pass**:
- ✓ All tests pass (100%)
- ✓ Coverage ≥ 90%
- ✓ Performance <100ms (P95)
- ✓ No forbidden words in message bank
- ✓ Accessibility axe-core score 100%

**User validation pass**:
- ✓ Emotional response >80% positive (MANDATORY)
- ✓ Comprehension >90%
- ✓ Tone appropriateness <20% negative
- ✓ Pedagogical expert approval (MANDATORY)

---

## Recommended Test Execution Order

**Local Development** (fast feedback loop):
1. Unit tests for current file (watch mode)
2. Forbidden words check (pre-commit)
3. Related integration tests
4. Pre-commit: All unit tests

**CI/CD Pipeline** (optimized for failure detection):
1. **Fail Fast** (0-3 min):
   - P0 unit tests
   - Lint + type check
   - Forbidden words validation
2. **Core Functionality** (3-12 min):
   - All unit tests
   - P0 integration tests (module integration)
   - Performance benchmarks (<100ms)
3. **Full Validation** (12-30 min):
   - All integration tests
   - E2E P0 tests
   - Accessibility automated (axe-core)
4. **Comprehensive** (30-60 min):
   - All E2E tests
   - Accessibility manual (screen readers - manual trigger)
   - Performance stress tests

**Pre-Release** (full suite + user testing):
- All automated tests (P0, P1, P2)
- User testing sessions (12-18 students) - **MANDATORY**
- Pedagogical expert review - **MANDATORY**
- Screen reader testing (NVDA, JAWS, VoiceOver)
- Cross-browser E2E (Chromium, Firefox, WebKit)

---

## Test Maintenance Strategy

### Test Reviews
- Code review includes tests
- User testing results reviewed by team
- Pedagogical expert review documented
- Test coverage tracked in PR

### Test Refactoring
- Extract common feedback scenarios to shared fixtures
- Page Object Model for E2E tests
- Custom matchers for feedback validation
- Forbidden words list maintained in separate file

### Test Documentation
- Each test has clear Given-When-Then comment
- User testing protocol documented (recruitment, sessions, analysis)
- Pedagogical quality checklist maintained
- Accessibility testing checklist maintained

---

## Future Test Enhancements

**After MVP** (Epic 1 complete):
- A/B testing result analysis automation
- Longitudinal engagement tracking (do students return?)
- Cross-cultural validation (if multi-region)
- Emotion detection (facial expression analysis - advanced)
- Teacher feedback collection automation

**Performance Monitoring** (Post-launch):
- Real User Monitoring (RUM) for P95 latency
- Performance regression detection
- Device performance correlation
- Network performance correlation

---

## Special Testing Considerations for US-003

### User Testing is NOT Optional

**Traditional QA**: Code works → Ship
**US-003 QA**: Code works + Students respond positively → Ship

**Implications**:
- User testing sessions scheduled in Sprint 2-3 (before deployment)
- Emotional response >80% positive is a **GATE BLOCKER**
- No deployment without validated student experience
- Iteration based on user feedback is expected

### Performance Testing is Critical Path

<100ms is aggressive. Performance testing must be:
- Continuous (every commit)
- Component-level (identify bottlenecks)
- Device-diverse (low-end testing)
- Production-realistic (RUM post-launch)

### Accessibility Testing is P0, Not P2

For educational software serving vulnerable populations:
- Screen reader testing is **MANDATORY**
- Keyboard navigation is **MANDATORY**
- WCAG AA compliance is **MANDATORY**
- Not "nice to have" - it's educational equity

### Pedagogical Expert Review is Quality Gate

**Code review**: Architect reviews technical quality
**Pedagogical review**: Expert reviews educational quality

Both are **MANDATORY** for US-003.

---

## Appendix: Test Scenario IDs

### Naming Convention
```
{epic}.{story}-{LEVEL}-{SEQ}
Example: 1.003-UNIT-001, 1.003-USER-001
```

**LEVEL**:
- UNIT: Unit test
- INT: Integration test
- E2E: End-to-end test
- PERF: Performance test
- ACC: Accessibility test
- USER: User testing (with students)

**SEQ**: Sequential number starting from 001

### Full Test ID Index

**Unit (15)**: 1.003-UNIT-001 through 1.003-UNIT-015
**Integration (15)**: 1.003-INT-001 through 1.003-INT-015
**E2E (5)**: 1.003-E2E-001 through 1.003-E2E-005
**Performance (9)**: 1.003-PERF-001 through 1.003-PERF-009
**Accessibility (3)**: 1.003-ACC-001 through 1.003-ACC-003
**User Testing (5)**: 1.003-USER-001 through 1.003-USER-005

**Total**: 52 test scenarios (includes performance/accessibility variants)

**GATE BLOCKERS**:
- 1.003-USER-002: Emotional response >80% positive
- 1.003-PERF-001: Feedback display <100ms (P95)
- 1.003-ACC-001/002/003: Screen reader compatibility
- Pedagogical expert approval (not automated test, but MANDATORY)
