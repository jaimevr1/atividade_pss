# Test Design: Story 1.001 - Sistema Runtime de Módulos

Date: 2025-10-01
Designer: Quinn (Test Architect)

## Test Strategy Overview

- **Total test scenarios**: 28
- **Unit tests**: 14 (50%)
- **Integration tests**: 10 (36%)
- **E2E tests**: 4 (14%)
- **Priority distribution**: P0: 12, P1: 10, P2: 6

**Approach**: Shift-left strategy focusing on unit tests for business logic, integration tests for component interaction, and targeted E2E tests for critical user journeys.

---

## Test Scenarios by Acceptance Criteria

### AC-1: JSON Configuration Loading

#### Scenarios

| ID | Level | Priority | Test Scenario | Justification |
|---|---|---|---|---|
| 1.001-UNIT-001 | Unit | P0 | Validate correct JSON schema parsing | Pure validation logic, fast feedback |
| 1.001-UNIT-002 | Unit | P0 | Reject invalid JSON structure | Schema validation error paths |
| 1.001-UNIT-003 | Unit | P0 | Validate moduleType whitelist | Security - prevent unknown types |
| 1.001-UNIT-004 | Unit | P1 | Validate config parameter types | Type safety for module configs |
| 1.001-UNIT-005 | Unit | P1 | Validate metadata structure | BNCC codes, difficulty, duration |
| 1.001-INT-001 | Integration | P0 | Load ModuleRuntime with valid config | Multi-component: Validator → Loader → Runtime |
| 1.001-INT-002 | Integration | P0 | Initialize module state correctly | State management integration |
| 1.001-E2E-001 | E2E | P1 | Complete config-to-render flow | Critical path: JSON → UI |

**Coverage**: AC-1 fully covered with 8 scenarios

**Risk Mitigations**:
- SEC-001 (JSON injection) → UNIT-003 whitelist validation
- TECH-001 (loading complexity) → INT-001, INT-002
- TECH-002 (schema versioning) → UNIT-001, UNIT-002

---

### AC-2: Dynamic Component Rendering

#### Scenarios

| ID | Level | Priority | Test Scenario | Justification |
|---|---|---|---|---|
| 1.001-UNIT-006 | Unit | P0 | ModuleLoader resolves correct component | Pure logic for type→component mapping |
| 1.001-UNIT-007 | Unit | P1 | Apply configuration parameters | Config application logic |
| 1.001-UNIT-008 | Unit | P1 | Verify design system token usage | Colors, typography validation |
| 1.001-INT-003 | Integration | P0 | Render BateriaRápida module | MVP module type M1 |
| 1.001-INT-004 | Integration | P0 | Render IdentificaOperação module | MVP module type M5 |
| 1.001-INT-005 | Integration | P0 | Render AutoAvaliação module | MVP module type M14 |
| 1.001-INT-006 | Integration | P1 | Responsive design 1024px+ | Multi-device testing |
| 1.001-INT-007 | Integration | P2 | Design system compliance | Visual regression |
| 1.001-E2E-002 | E2E | P1 | Student interacts with rendered module | User journey validation |

**Coverage**: AC-2 fully covered with 9 scenarios

**Risk Mitigations**:
- TECH-001 (component loading) → UNIT-006, INT-003/004/005
- PERF-001 (multiple modules) → INT-003/004/005 as baseline

---

### AC-3: Error Handling

#### Scenarios

| ID | Level | Priority | Test Scenario | Justification |
|---|---|---|---|---|
| 1.001-UNIT-009 | Unit | P0 | Error boundary catches component errors | Error isolation logic |
| 1.001-UNIT-010 | Unit | P0 | Generate friendly error messages | Error message formatting |
| 1.001-UNIT-011 | Unit | P0 | Log technical error details | Logging functionality |
| 1.001-UNIT-012 | Unit | P1 | Classify error severity | Error categorization logic |
| 1.001-INT-008 | Integration | P0 | Error boundary prevents crash | Full error containment |
| 1.001-INT-009 | Integration | P0 | User can continue with other modules | Error isolation between modules |
| 1.001-INT-010 | Integration | P1 | State recovery after error | State persistence integration |
| 1.001-E2E-003 | E2E | P0 | Graceful degradation on network failure | Critical reliability path |
| 1.001-E2E-004 | E2E | P1 | User recovers from corrupted config | Error recovery journey |

**Coverage**: AC-3 fully covered with 9 scenarios

**Risk Mitigations**:
- DATA-001 (state loss) → INT-010
- REL-001 (cascading failures) → INT-009
- OPS-001 (debugging) → UNIT-010, UNIT-011

---

## Performance & Non-Functional Tests

| ID | Level | Priority | Test Scenario | Target | Justification |
|---|---|---|---|---|---|
| 1.001-UNIT-013 | Unit | P0 | JSON validation performance | <100ms | Perf requirement |
| 1.001-UNIT-014 | Unit | P1 | Module initialization time | <2s | Perf requirement |
| 1.001-INT-011 | Integration | P0 | Memory usage per module | <50MB | Perf requirement |
| 1.001-INT-012 | Integration | P1 | 3 modules simultaneously | No degradation | PERF-001 mitigation |
| 1.001-INT-013 | Integration | P2 | 5 modules stress test | Graceful degradation | PERF-001 validation |
| 1.001-E2E-005 | E2E | P2 | Network throttling (3G) | Usable experience | Accessibility |

**Coverage**: All performance requirements testable

**Risk Mitigations**:
- PERF-001 (multi-module) → INT-012, INT-013
- PERF-002 (cold start) → UNIT-014, E2E-005

---

## Risk Coverage Matrix

| Risk ID | Score | Related Test Scenarios | Coverage |
|---|---|---|---|
| TECH-001 | 9 | UNIT-006, INT-001, INT-002, INT-003/004/005 | ✓ Full |
| SEC-001 | 9 | UNIT-001, UNIT-002, UNIT-003, Security tests* | ✓ Full |
| PERF-001 | 6 | INT-012, INT-013, UNIT-013 | ✓ Full |
| DATA-001 | 6 | INT-010, E2E-004 | ✓ Partial |
| TECH-002 | 6 | UNIT-001, UNIT-002 (+ version tests*) | ○ Baseline |
| OPS-001 | 4 | UNIT-010, UNIT-011 | ✓ Full |
| REL-001 | 4 | INT-008, INT-009 | ✓ Full |
| PERF-002 | 4 | UNIT-014, E2E-005 | ✓ Full |

\* Additional security testing required (see Security Test Addendum)

---

## Security Test Addendum

**Priority**: P0 (Must complete before production)

| ID | Test Type | Scenario | Tool/Method |
|---|---|---|---|
| 1.001-SEC-001 | Security | XSS injection via config strings | Manual + OWASP ZAP |
| 1.001-SEC-002 | Security | Code injection via moduleType | Fuzzing tool |
| 1.001-SEC-003 | Security | JSON bomb (deeply nested) | Load testing |
| 1.001-SEC-004 | Security | CSP violation attempts | Browser DevTools |
| 1.001-SEC-005 | Security | Schema validation bypass | Manual testing |

**Recommendation**: Add security testing to CI/CD pipeline with automated OWASP checks.

---

## Test Implementation Priority

### Phase 1: P0 Tests (Critical - Block Release)

**Unit Tests** (6-8 hours):
- 1.001-UNIT-001: Valid JSON parsing
- 1.001-UNIT-002: Invalid JSON rejection
- 1.001-UNIT-003: ModuleType whitelist
- 1.001-UNIT-006: Component resolution
- 1.001-UNIT-009: Error boundary logic
- 1.001-UNIT-010: Friendly error messages
- 1.001-UNIT-011: Error logging
- 1.001-UNIT-013: Validation performance <100ms

**Integration Tests** (8-12 hours):
- 1.001-INT-001: Load runtime with config
- 1.001-INT-002: Initialize state
- 1.001-INT-003/004/005: Render all 3 MVP modules
- 1.001-INT-008: Error boundary prevents crash
- 1.001-INT-009: Module isolation on error
- 1.001-INT-011: Memory usage <50MB

**E2E Tests** (4-6 hours):
- 1.001-E2E-003: Network failure graceful degradation

**Security Tests** (8-10 hours):
- 1.001-SEC-001 through 1.001-SEC-005

**Total Phase 1**: ~30-40 hours

---

### Phase 2: P1 Tests (Important - Ship with Known Gaps)

**Unit Tests** (4-6 hours):
- 1.001-UNIT-004: Config parameter types
- 1.001-UNIT-005: Metadata structure
- 1.001-UNIT-007: Apply config parameters
- 1.001-UNIT-008: Design system tokens
- 1.001-UNIT-012: Error severity
- 1.001-UNIT-014: Init time <2s

**Integration Tests** (6-8 hours):
- 1.001-INT-006: Responsive 1024px+
- 1.001-INT-010: State recovery
- 1.001-INT-012: 3 modules simultaneously

**E2E Tests** (4-6 hours):
- 1.001-E2E-001: Config-to-render flow
- 1.001-E2E-002: Student interaction
- 1.001-E2E-004: Error recovery journey

**Total Phase 2**: ~14-20 hours

---

### Phase 3: P2 Tests (Nice to Have - Future Optimization)

**Integration Tests** (4-6 hours):
- 1.001-INT-007: Design system compliance (visual regression)
- 1.001-INT-013: 5 modules stress test

**E2E Tests** (2-3 hours):
- 1.001-E2E-005: Network throttling 3G

**Total Phase 3**: ~6-9 hours

---

## Test Data Requirements

### Valid Configurations

**Config Set 1: BateriaRápida (M1)**
```json
{
  "moduleType": "BateriaRápida",
  "config": {
    "operationType": "division",
    "numberRange": { "min": 10, "max": 100 },
    "quantity": 30,
    "timeLimit": null
  },
  "metadata": {
    "estimatedDuration": 15,
    "bnccCodes": ["EF05MA03"],
    "difficulty": "intermediate"
  }
}
```

**Config Set 2: IdentificaOperação (M5)**
```json
{
  "moduleType": "IdentificaOperação",
  "config": {
    "scenarios": 10,
    "includeOperations": ["addition", "subtraction", "multiplication", "division"]
  },
  "metadata": {
    "estimatedDuration": 10,
    "bnccCodes": ["EF05MA03"],
    "difficulty": "basic"
  }
}
```

**Config Set 3: AutoAvaliação (M14)**
```json
{
  "moduleType": "AutoAvaliação",
  "config": {
    "questions": [
      "Como você se sentiu durante a atividade?",
      "O que foi mais difícil?"
    ]
  },
  "metadata": {
    "estimatedDuration": 5,
    "bnccCodes": [],
    "difficulty": "basic"
  }
}
```

### Invalid Configurations (Error Testing)

**Invalid 1: Unknown module type**
```json
{
  "moduleType": "HackerModule",
  "config": {}
}
```

**Invalid 2: Missing required fields**
```json
{
  "config": { "operationType": "division" }
}
```

**Invalid 3: Type mismatch**
```json
{
  "moduleType": "BateriaRápida",
  "config": {
    "operationType": 123,
    "numberRange": "invalid"
  }
}
```

**Invalid 4: XSS injection attempt**
```json
{
  "moduleType": "BateriaRápida",
  "config": {
    "operationType": "<script>alert('XSS')</script>"
  }
}
```

**Invalid 5: JSON bomb (deeply nested)**
```json
{
  "moduleType": "BateriaRápida",
  "config": {
    "nested": { "level1": { "level2": { ... (100 levels deep) } } }
  }
}
```

---

## Mock/Stub Strategy

### Unit Test Mocks

**ModuleLoader mocks**:
- Mock React.lazy to return test components
- Stub dynamic import to avoid actual file loading
- Fake component registry for type mapping

**ModuleValidator mocks**:
- Mock JSON schema library (Zod/Ajv)
- Stub schema definitions

**Error Boundary mocks**:
- Mock logging service
- Stub error tracking (Sentry)

### Integration Test Mocks

**Minimal mocking** (real components preferred):
- Mock external services only (logging, analytics)
- Stub network calls for reliability
- Use test harness for module types

### E2E Test Mocks

**No mocking** (real system):
- Real components
- Real validation
- Real error boundaries
- Mock only: Backend APIs (if applicable)

---

## Test Environment Requirements

### Unit Tests
- **Framework**: Vitest (fast, Vite-aligned)
- **Assertion**: Expect API (built-in)
- **Mocking**: vi.mock (built-in)
- **Coverage**: c8 (built-in)

### Integration Tests
- **Framework**: Vitest + React Testing Library
- **Rendering**: @testing-library/react
- **User events**: @testing-library/user-event
- **Assertions**: @testing-library/jest-dom

### E2E Tests
- **Framework**: Playwright
- **Browsers**: Chromium, Firefox, WebKit
- **Viewports**: Desktop (1920x1080), Tablet (1024x768)
- **Network**: Fast 3G, Slow 3G, Offline

### Performance Tests
- **Profiling**: React DevTools Profiler
- **Memory**: Chrome DevTools Memory
- **Bundle analysis**: rollup-plugin-visualizer
- **Load testing**: k6 (future)

### Security Tests
- **Static analysis**: ESLint security plugins
- **Dynamic testing**: OWASP ZAP
- **Dependency scanning**: npm audit, Snyk

---

## Continuous Integration Strategy

### Pre-commit Hooks
- ESLint + Prettier
- Type checking (TypeScript)
- Unit tests for changed files

### PR Pipeline
1. **Fast checks** (~2 min):
   - Lint
   - Type check
   - Unit tests (all)
2. **Integration tests** (~5 min):
   - Component integration
   - Memory profiling
3. **Security scan** (~3 min):
   - npm audit
   - ESLint security rules
4. **Build verification** (~2 min):
   - Production build
   - Bundle size check

### Main Branch Pipeline
- All PR checks +
- E2E tests (~10 min)
- Security testing (OWASP ZAP) (~15 min)
- Performance benchmarks (~5 min)
- Coverage report (Codecov)

---

## Test Quality Metrics

### Coverage Targets

**Overall**: 90%+ (per DoD)

**By Component**:
- ModuleValidator: 95%+ (critical security)
- ModuleLoader: 90%+ (complex logic)
- ModuleRuntime: 90%+ (orchestration)
- Error boundaries: 100% (safety critical)

**By Type**:
- Statements: 90%+
- Branches: 85%+
- Functions: 90%+
- Lines: 90%+

### Performance Targets

**Test execution time**:
- Unit tests: <5 seconds (all)
- Integration tests: <30 seconds (all)
- E2E tests: <2 minutes (all)

**Build time**:
- Development build: <3 seconds
- Production build: <10 seconds

### Quality Gates

**Automated checks pass**:
- ✓ All tests pass (100%)
- ✓ Coverage ≥ 90%
- ✓ No security vulnerabilities (high/critical)
- ✓ Bundle size within budget
- ✓ Performance targets met

---

## Recommended Test Execution Order

**Local Development** (fast feedback loop):
1. Unit tests for current file (watch mode)
2. Related integration tests
3. Pre-commit: All unit tests

**CI/CD Pipeline** (optimized for failure detection):
1. **Fail Fast** (0-3 min):
   - P0 unit tests
   - Lint + type check
2. **Core Functionality** (3-10 min):
   - All unit tests
   - P0 integration tests
   - Security baseline
3. **Full Validation** (10-30 min):
   - All integration tests
   - E2E P0 tests
   - Performance tests
4. **Comprehensive** (30-45 min):
   - All E2E tests
   - Security penetration tests
   - Visual regression

**Pre-Release** (full suite):
- All tests (P0, P1, P2)
- Full security audit
- Performance benchmarking
- Cross-browser E2E
- Accessibility audit

---

## Test Maintenance Strategy

### Test Reviews
- Code review includes tests
- Test coverage tracked in PR
- Flaky tests fixed within 24h or disabled

### Test Refactoring
- Extract common fixtures to shared module
- Page Object Model for E2E tests
- Custom matchers for domain logic

### Test Documentation
- Each test has clear Given-When-Then comment
- Complex test setups documented
- Test data generation explained

---

## Future Test Enhancements

**After MVP** (Epic 1 complete):
- Visual regression testing (Percy, Chromatic)
- Accessibility automation (axe-core)
- Load testing (k6 for concurrent users)
- Mutation testing (Stryker)
- Contract testing (if backend APIs)

**Performance Monitoring** (Post-launch):
- Real User Monitoring (RUM)
- Synthetic monitoring
- Error rate alerting
- Performance budgets in CI

---

## Appendix: Test Scenario IDs

### Naming Convention
```
{epic}.{story}-{LEVEL}-{SEQ}
Example: 1.001-UNIT-001
```

**LEVEL**:
- UNIT: Unit test
- INT: Integration test
- E2E: End-to-end test
- SEC: Security test
- PERF: Performance test

**SEQ**: Sequential number starting from 001

### Full Test ID Index

**Unit (14)**: 1.001-UNIT-001 through 1.001-UNIT-014
**Integration (13)**: 1.001-INT-001 through 1.001-INT-013
**E2E (5)**: 1.001-E2E-001 through 1.001-E2E-005
**Security (5)**: 1.001-SEC-001 through 1.001-SEC-005

**Total**: 37 test scenarios (28 functional + 5 security + 4 performance-focused)
